"""
ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
Phase 3.3: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
"""
import time
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
import sys

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


@dataclass
class PerformanceMetric:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: str
    operation: str
    duration_ms: float
    success: bool
    details: Dict = None
    
    def to_dict(self):
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'timestamp': self.timestamp,
            'operation': self.operation,
            'duration_ms': round(self.duration_ms, 2),
            'success': self.success,
            'details': self.details or {}
        }


class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, log_dir: str = "logs/metrics"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.metrics: List[PerformanceMetric] = []
        self.logger = logging.getLogger(__name__)
    
    def measure(self, operation: str):
        """ë°ì½”ë ˆì´í„°: í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                start_time = time.time()
                success = False
                error = None
                result = None
                
                try:
                    result = func(*args, **kwargs)
                    success = True
                except Exception as e:
                    error = str(e)
                    raise
                finally:
                    duration = (time.time() - start_time) * 1000  # ms
                    
                    metric = PerformanceMetric(
                        timestamp=datetime.now().isoformat(),
                        operation=operation,
                        duration_ms=duration,
                        success=success,
                        details={'error': error} if error else {}
                    )
                    
                    self.record(metric)
                    
                    # ë¡œê¹…
                    if success:
                        self.logger.info(f"âœ… {operation}: {duration:.2f}ms")
                    else:
                        self.logger.error(f"âŒ {operation}: {duration:.2f}ms (ì‹¤íŒ¨: {error})")
                
                return result
            return wrapper
        return decorator
    
    def record(self, metric: PerformanceMetric):
        """ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.metrics.append(metric)
    
    def record_manual(self, operation: str, duration_ms: float, success: bool = True, details: Dict = None):
        """ìˆ˜ë™ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        metric = PerformanceMetric(
            timestamp=datetime.now().isoformat(),
            operation=operation,
            duration_ms=duration_ms,
            success=success,
            details=details
        )
        self.record(metric)
    
    def save_metrics(self, filename: str = None):
        """ë©”íŠ¸ë¦­ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            filename = f"metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        filepath = self.log_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(
                [m.to_dict() for m in self.metrics],
                f,
                indent=2,
                ensure_ascii=False
            )
        
        self.logger.info(f"ğŸ“Š ë©”íŠ¸ë¦­ ì €ì¥: {filepath}")
        return str(filepath)
    
    def get_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ í†µê³„"""
        if not self.metrics:
            return {'message': 'ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ ì—†ìŒ'}
        
        # ì‘ì—…ë³„ ê·¸ë£¹í™”
        ops = {}
        for m in self.metrics:
            if m.operation not in ops:
                ops[m.operation] = {
                    'count': 0,
                    'total_duration': 0,
                    'success_count': 0,
                    'durations': []
                }
            
            ops[m.operation]['count'] += 1
            ops[m.operation]['total_duration'] += m.duration_ms
            if m.success:
                ops[m.operation]['success_count'] += 1
            ops[m.operation]['durations'].append(m.duration_ms)
        
        # í†µê³„ ê³„ì‚°
        summary = {}
        for op, data in ops.items():
            durations = sorted(data['durations'])
            avg = data['total_duration'] / data['count']
            
            summary[op] = {
                'í˜¸ì¶œ_íšŸìˆ˜': data['count'],
                'ì„±ê³µë¥ ': f"{data['success_count'] / data['count'] * 100:.1f}%",
                'í‰ê· _ì‹œê°„_ms': round(avg, 2),
                'ìµœì†Œ_ì‹œê°„_ms': round(min(durations), 2),
                'ìµœëŒ€_ì‹œê°„_ms': round(max(durations), 2),
                'p50_ms': round(durations[len(durations)//2], 2),
                'p95_ms': round(durations[int(len(durations)*0.95)], 2) if len(durations) > 1 else round(durations[0], 2)
            }
        
        return summary
    
    def print_summary(self):
        """ìš”ì•½ ì¶œë ¥"""
        summary = self.get_summary()
        
        print("\n" + "=" * 80)
        print("ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìš”ì•½")
        print("=" * 80)
        
        if 'message' in summary:
            print(summary['message'])
            return
        
        for op, stats in summary.items():
            print(f"\nğŸ“Š {op}:")
            for key, value in stats.items():
                print(f"  - {key}: {value}")
        
        print("\n" + "=" * 80)


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] %(message)s')
    
    monitor = PerformanceMonitor()
    
    print("=" * 80)
    print("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # COA í‰ê°€ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¸¡ì •
    try:
        from core_pipeline.coa_scorer import COAScorer
        from core_pipeline.relevance_mapper import RelevanceMapper
        from core_pipeline.resource_priority_parser import ResourcePriorityParser
        
        # 1. RelevanceMapper ì´ˆê¸°í™” ì¸¡ì •
        start = time.time()
        mapper = RelevanceMapper()
        duration = (time.time() - start) * 1000
        monitor.record_manual("RelevanceMapper ì´ˆê¸°í™”", duration)
        
        # 2. ResourcePriorityParser ì´ˆê¸°í™” ì¸¡ì •
        start = time.time()
        parser = ResourcePriorityParser()
        duration = (time.time() - start) * 1000
        monitor.record_manual("ResourcePriorityParser ì´ˆê¸°í™”", duration)
        
        # 3. COAScorer ì´ˆê¸°í™” ì¸¡ì •
        start = time.time()
        scorer = COAScorer(coa_type="defense")
        duration = (time.time() - start) * 1000
        monitor.record_manual("COAScorer ì´ˆê¸°í™”", duration)
        
        # 4. ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° ì¸¡ì • (10íšŒ)
        for i in range(10):
            start = time.time()
            score = mapper.get_relevance_score(
                coa_id=f"COA_DEF_{i:03d}",
                coa_type="Defense",
                threat_id=f"THR{i:03d}",
                threat_type="ì¹¨íˆ¬"
            )
            duration = (time.time() - start) * 1000
            monitor.record_manual("ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°", duration, details={'score': score})
        
        # 5. ìì› ìš°ì„ ìˆœìœ„ íŒŒì‹± ì¸¡ì • (10íšŒ)
        test_strings = [
            "í¬ë³‘ëŒ€ëŒ€(í•„ìˆ˜), ë³´ë³‘ì—¬ë‹¨(ê¶Œì¥)",
            "ì „ì°¨ëŒ€ëŒ€(í•„ìˆ˜), ê³µë³‘ëŒ€ëŒ€(ì„ íƒ)",
            "íŠ¹ìˆ˜ì „íŒ€(í•„ìˆ˜), ì‚¬ì´ë²„ì „íŒ€(ê¶Œì¥), ì •ë³´ë¶€ëŒ€(ì„ íƒ)",
        ]
        for i in range(10):
            test_str = test_strings[i % len(test_strings)]
            start = time.time()
            result = parser.parse_resource_priority(test_str)
            duration = (time.time() - start) * 1000
            monitor.record_manual("ìì› ìš°ì„ ìˆœìœ„ íŒŒì‹±", duration, details={'parsed_count': len(result)})
        
        # 6. COA ì ìˆ˜ ê³„ì‚° ì¸¡ì • (5íšŒ)
        for i in range(5):
            context = {
                'coa_uri': f'http://example.org#COA_DEF_{i:03d}',
                'coa_id': f'COA_DEF_{i:03d}',
                'coa_type': 'Defense',
                'threat_type': 'ì¹¨íˆ¬',
                'threat_level': 0.8,
                'environment_fit': 0.9,
                'expected_success_rate': 0.65,
                'chain_info': {'chains': [{'path': 'c1', 'avg_confidence': 0.7}]},
                'resource_priority_string': 'í¬ë³‘ëŒ€ëŒ€(í•„ìˆ˜), ë³´ë³‘ì—¬ë‹¨(ê¶Œì¥)',
                'available_resources': [
                    {'resource_name': 'í¬ë³‘ëŒ€ëŒ€', 'available_quantity': 18, 'status': 'ì‚¬ìš©ê°€ëŠ¥'},
                ],
                'is_first_coa': i == 0
            }
            
            start = time.time()
            result = scorer.calculate_score(context)
            duration = (time.time() - start) * 1000
            monitor.record_manual(
                "COA ì¢…í•© ì ìˆ˜ ê³„ì‚°", 
                duration, 
                details={'total_score': result['total']}
            )
        
        # ìš”ì•½ ì¶œë ¥
        monitor.print_summary()
        
        # ì €ì¥
        filepath = monitor.save_metrics()
        print(f"\nâœ… ë©”íŠ¸ë¦­ íŒŒì¼ ì €ì¥: {filepath}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
