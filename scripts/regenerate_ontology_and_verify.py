# scripts/regenerate_ontology_and_verify.py
# -*- coding: utf-8 -*-
import os
import sys
from pathlib import Path
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from core_pipeline.ontology_manager_enhanced import EnhancedOntologyManager
from core_pipeline.data_manager import DataManager

def main():
    print("=== ì˜¨í†¨ë¡œì§€ ì¬ìƒì„± ë° ìµœì¢… ê²€ì¦ ì‹œì‘ ===\n")
    
    # 1. ë°ì´í„° ë¡œë“œ
    config = {
        "data_lake_path": "data_lake",
        "metadata_path": "metadata",
        "ontology_path": "knowledge/ontology",
        "output_path": "outputs"
    }
    
    dm = DataManager(config)
    data = dm.load_all()
    print(f"âœ… {len(data)}ê°œ í…Œì´ë¸” ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    
    # 2. ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì € ì´ˆê¸°í™” ë° ìƒì„±
    om = EnhancedOntologyManager(config)
    print("ğŸ”„ ì˜¨í†¨ë¡œì§€ ìƒì„± ì¤‘ (instances, schema)...")
    
    # instances ìƒì„±
    om.generate_instances(data)
    
    # ì €ì¥ (knowledge/ontology í´ë”ì— ì €ì¥ë¨)
    success = om.save_graph(
        save_schema_separately=True,
        save_instances_separately=True,
        save_reasoned_separately=True,
        enable_semantic_inference=True
    )
    
    if success:
        print(f"âœ… ì˜¨í†¨ë¡œì§€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {config['ontology_path']}")
    else:
        print("âŒ ì˜¨í†¨ë¡œì§€ ì €ì¥ ì‹¤íŒ¨")
        return

    # 3. êµë¦¬ì  í†µí•© ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    print("\nğŸ”„ êµë¦¬ì  í†µí•© ì¬ê²€ì¦ ì¤‘...")
    import subprocess
    result = subprocess.run(["python", "scripts/verify_doctrinal_integration.py"], capture_output=True, text=True)
    print(result.stdout)
    
    if result.returncode == 0:
        print("ğŸ‰ ëª¨ë“  ê²€ì¦ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("âŒ êµë¦¬ì  í†µí•© ê²€ì¦ ì‹¤íŒ¨")
        print(result.stderr)

if __name__ == "__main__":
    main()
