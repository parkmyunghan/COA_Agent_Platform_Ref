"""
ì˜¨í†¨ë¡œì§€ ì¬ìƒì„± ë° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ì—…ë°ì´íŠ¸ëœ schema_registry.yamlì„ ì‚¬ìš©í•˜ì—¬ ì˜¨í†¨ë¡œì§€ë¥¼ ì¬ìƒì„±í•˜ê³ ,
ì£¼ìš” ê°ì²´ì™€ ê´€ê³„ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
"""
import sys
from pathlib import Path
import json
import pandas as pd

# ê²°ê³¼ íŒŒì¼ë¡œ ì¶œë ¥ ë¦¬ë‹¤ì´ë ‰ì…˜ (ë””ë²„ê¹…ìš©)
output_path = Path(__file__).parent.parent / "outputs" / "regen_debug.log"
sys.stdout = open(output_path, 'w', encoding='utf-8')
sys.stderr = sys.stdout

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from core_pipeline.ontology_manager_enhanced import EnhancedOntologyManager
    from rdflib import Graph, URIRef, Literal, Namespace
    from rdflib.namespace import RDF, RDFS, OWL
except ImportError as e:
    print(f"âŒ Import ì‹¤íŒ¨: {e}")
    sys.exit(1)

def load_all_excel_files(data_lake_path: Path):
    """ëª¨ë“  ì—‘ì…€ íŒŒì¼ ë¡œë“œ"""
    data = {}
    excel_files = list(data_lake_path.glob("*.xlsx"))
    print(f"ğŸ“‚ ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì¤‘... ({len(excel_files)}ê°œ)")
    
    for file_path in sorted(excel_files):
        try:
            # ì²« ë²ˆì§¸ ì‹œíŠ¸ë§Œ ë¡œë“œ
            df = pd.read_excel(file_path, sheet_name=0)
            table_name = file_path.stem
            data[table_name] = df
            print(f"  - {table_name}: {len(df)} í–‰")
        except Exception as e:
            print(f"  âŒ {file_path.name} ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return data

def generate_ontology():
    """ì˜¨í†¨ë¡œì§€ ì¬ìƒì„±"""
    print("\nğŸ”„ ì˜¨í†¨ë¡œì§€ ì¬ìƒì„± ì‹œì‘...")
    
    # ì„¤ì •
    data_lake_path = project_root / "data_lake"
    knowledge_dir = project_root / "knowledge"
    schema_path = project_root / "metadata" / "schema_registry.yaml"
    
    config = {
        "data_lake_dir": str(data_lake_path),
        "knowledge_dir": str(knowledge_dir),
        "schema_registry_path": str(schema_path),
        "base_uri": "http://example.org/ontology/",
        "force_refresh": True
    }
    
    # ë§¤ë‹ˆì € ì´ˆê¸°í™”
    manager = EnhancedOntologyManager(config)
    manager.clear_relation_mappings_cache()
    
    # ë°ì´í„° ë¡œë“œ
    data = load_all_excel_files(data_lake_path)
    
    # ê·¸ë˜í”„ ìƒì„± (build_from_data ì‚¬ìš©)
    try:
        g = manager.build_from_data(data, force_rebuild=True, auto_sync_schema=False)
        
        if g:
            print(f"âœ… ì˜¨í†¨ë¡œì§€ ìƒì„± ì™„ë£Œ. íŠ¸ë¦¬í”Œ ìˆ˜: {len(g)}")
            return g, manager
        else:
            print("âŒ ì˜¨í†¨ë¡œì§€ ìƒì„± ì‹¤íŒ¨ (ê·¸ë˜í”„ê°€ None ë°˜í™˜)")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ ì˜¨í†¨ë¡œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

def validate_ontology(g, manager):
    """ìƒì„±ëœ ì˜¨í†¨ë¡œì§€ ê²€ì¦"""
    print("\nğŸ” ì˜¨í†¨ë¡œì§€ ê²€ì¦ ì‹œì‘...")
    
    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„¤ì • (Manager ë‚´ë¶€ì˜ ns ì‚¬ìš©)
    NS = manager.ns
    
    # 1. ìœ„í˜‘ìƒí™© ì†ì„± ê²€ì¦
    print("\n[ê²€ì¦ 1] ìœ„í˜‘ìƒí™© ì†ì„± í™•ì¸")
    
    query_threat = f"""
    PREFIX : <{NS}>
    SELECT ?threat ?type ?level ?axis ?loc
    WHERE {{
        ?threat a :ìœ„í˜‘ìƒí™© .
        OPTIONAL {{ ?threat :ìœ„í˜‘ìœ í˜• ?type }}
        OPTIONAL {{ ?threat :ìœ„í˜‘ìˆ˜ì¤€ ?level }}
        OPTIONAL {{ ?threat :hasì „ì¥ì¶•ì„  ?axis }}
        OPTIONAL {{ ?threat :locatedIn ?loc }}
    }}
    LIMIT 5
    """
    
    try:
        results = g.query(query_threat)
        count = 0
        for row in results:
            count += 1
            print(f"  - Threat: {row.threat.split('#')[-1]}")
            print(f"    Type: {row.type}, Level: {row.level}")
            print(f"    Axis: {row.axis.split('#')[-1] if row.axis else 'None'}")
            print(f"    Loc: {row.loc.split('#')[-1] if row.loc else 'None'}")
        
        if count == 0:
            print("  âš ï¸ ìœ„í˜‘ìƒí™© ì¸ìŠ¤í„´ìŠ¤ê°€ ì¡°íšŒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"  âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    # 2. COA ì†ì„± ê²€ì¦
    print("\n[ê²€ì¦ 2] COA ë¼ì´ë¸ŒëŸ¬ë¦¬ ì†ì„± í™•ì¸ (ìƒˆë¡œ ì¶”ê°€ëœ ì†ì„±)")
    query_coa = f"""
    PREFIX : <{NS}>
    SELECT ?coa ?name ?res ?wargame
    WHERE {{
        ?coa a :COA_Library .
        OPTIONAL {{ ?coa :ëª…ì¹­ ?name }}
        OPTIONAL {{ ?coa :í•„ìš”ìì› ?res }}
        OPTIONAL {{ ?coa :ì›Œê²Œì„_ëª¨ì˜_ë¶„ì„_ìŠ¹ë¥  ?wargame }}
    }}
    LIMIT 5
    """
    
    try:
        results = g.query(query_coa)
        count = 0
        for row in results:
            count += 1
            print(f"  - COA: {row.coa.split('#')[-1]}")
            print(f"    Name: {row.name}")
            print(f"    Resource: {row.res}")
            print(f"    Wargame: {row.wargame}")
            
        if count == 0:
            print("  âš ï¸ COA ì¸ìŠ¤í„´ìŠ¤ê°€ ì¡°íšŒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"  âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    # 3. ì„ë¬´ì •ë³´ ê´€ê³„ ê²€ì¦
    print("\n[ê²€ì¦ 3] ì„ë¬´ì •ë³´-ì¶•ì„  ê´€ê³„ í™•ì¸")
    query_mission = f"""
    PREFIX : <{NS}>
    SELECT ?mission ?main_axis ?sub_axis
    WHERE {{
        ?mission a :ì„ë¬´ì •ë³´ .
        OPTIONAL {{ ?mission :hasì „ì¥ì¶•ì„  ?main_axis }} 
    }}
    LIMIT 5
    """
    try:
        results = g.query(query_mission)
        for row in results:
             print(f"  - Mission: {row.mission.split('#')[-1]}")
             print(f"    Axis: {row.main_axis.split('#')[-1] if row.main_axis else 'None'}")
    except Exception as e:
        print(f"  âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    print("\nâœ… ê²€ì¦ ì™„ë£Œ")

if __name__ == "__main__":
    g, manager = generate_ontology()
    validate_ontology(g, manager)
