# ui/components/dashboard_tab_settings.py
# -*- coding: utf-8 -*-
"""
íƒ­ 4: ì„¤ì • ë° ê´€ë¦¬
"""
import streamlit as st
from ui.components.palantir_mode_toggle import render_palantir_mode_toggle
from ui.components.data_panel import render_data_panel
from ui.components.doc_manager import render_doc_manager


def render_settings_tab(orchestrator, config):
    """íƒ­ 4: ì„¤ì • ë° ê´€ë¦¬"""
    
    st.header("ì„¤ì • ë° ê´€ë¦¬")
    st.markdown("ì‹œìŠ¤í…œ ì„¤ì • ë° ë°ì´í„° ê´€ë¦¬")
    
    # ì‹œìŠ¤í…œ ì„¤ì •
    st.subheader("ì‹œìŠ¤í…œ ì„¤ì •")
    
    # í˜„ì¬ LLM ëª¨ë¸ í‘œì‹œ (ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ë™ì  ì—…ë°ì´íŠ¸)
    llm_manager = orchestrator.core.llm_manager
    st.markdown("#### í˜„ì¬ LLM ëª¨ë¸")
    selected_model_key = llm_manager.selected_model_key
    
    # ì„ íƒëœ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    if not selected_model_key:
        if llm_manager.openai_available and llm_manager.use_openai:
            selected_model_key = 'openai'
        elif llm_manager.model is not None:
            selected_model_key = 'local'
        else:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ ì°¾ê¸°
            available_models = llm_manager.get_available_models()
            for model_key, model_info in available_models.items():
                if model_info.get('available', False):
                    selected_model_key = model_key
                    break
    
    # ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ ëª¨ë¸ëª… í‘œì‹œ
    if selected_model_key == 'openai':
        model_name = llm_manager.openai_model if llm_manager.openai_available else "OpenAI (ì‚¬ìš© ë¶ˆê°€)"
        st.info(f"**OpenAI API**: {model_name}")
        st.caption("ì°¸ê³ : OpenAI APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ëª¨ë¸ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤.")
    elif selected_model_key == 'local':
        if llm_manager.model is not None:
            model_path = llm_manager.model_path or "ë¡œì»¬ ëª¨ë¸"
            if model_path:
                import os
                model_name = os.path.basename(model_path) if model_path else "ë¡œì»¬ ëª¨ë¸"
                st.info(f"**ë¡œì»¬ ëª¨ë¸**: {model_name}")
                st.caption(f"ê²½ë¡œ: {model_path}")
            else:
                st.info("**ë¡œì»¬ ëª¨ë¸**: ê²½ë¡œ ì •ë³´ ì—†ìŒ")
        else:
            st.warning("**ë¡œì»¬ ëª¨ë¸**: ë¯¸ë¡œë“œ")
            st.caption("ì°¸ê³ : ë¡œì»¬ ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Agent ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.")
    elif selected_model_key and selected_model_key.startswith('internal_'):
        # ì‚¬ë‚´ë§ ëª¨ë¸
        model_key = selected_model_key.replace('internal_', '')
        if model_key in llm_manager.internal_models:
            model_info = llm_manager.internal_models[model_key]
            model_name = model_info.get('name', model_key)
            model_url = model_info.get('url', '')
            st.info(f"**ì‚¬ë‚´ë§ ëª¨ë¸**: {model_name}")
            st.caption(f"URL: {model_url}")
        else:
            st.warning(f"**ì‚¬ë‚´ë§ ëª¨ë¸**: {model_key} (ì„¤ì • ì—†ìŒ)")
    else:
        st.warning("[WARN] ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.caption("ì°¸ê³ : ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.")
    
    st.divider()
    
    # íŒ”ë€í‹°ì–´ ëª¨ë“œ í† ê¸€
    render_palantir_mode_toggle(key_prefix="settings_")
    
    st.divider()
    
    # ë‹¨ê³„ë³„ í˜ì´ì§€ë¡œ ì´ë™
    st.subheader("ë‹¨ê³„ë³„ í˜ì´ì§€")
    st.markdown("""
    ì„¸ë¶€ ì›Œí¬í”Œë¡œìš°ëŠ” ë‹¤ìŒ ë‹¨ê³„ë³„ í˜ì´ì§€ì—ì„œ ìˆ˜í–‰í•˜ì„¸ìš”:
    
    - **1ë‹¨ê³„: ë°ì´í„° ê´€ë¦¬** - ë°ì´í„° ë¡œë“œ, í¸ì§‘, ê²€ì¦
    - **2ë‹¨ê³„: ì˜¨í†¨ë¡œì§€ ìƒì„±** - ê·¸ë˜í”„ ìƒì„± ë° ê´€ê³„ ê´€ë¦¬
    - **3ë‹¨ê³„: ì§€ì‹ê·¸ë˜í”„ ì¡°íšŒ** - SPARQL ì¿¼ë¦¬ ë° ê·¸ë˜í”„ íƒìƒ‰
    - **4ë‹¨ê³„: RAG ì¸ë±ìŠ¤ êµ¬ì„±** - ë¬¸ì„œ ì—…ë¡œë“œ ë° ì¸ë±ìŠ¤ ê´€ë¦¬
    - **5ë‹¨ê³„: Agent ì‹¤í–‰** - LLM ì§ˆë¬¸ ë° ìƒì„¸ ìƒí˜¸ì‘ìš©
    - **6ë‹¨ê³„: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§** - ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí¬
    
    ğŸ’¡ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ê° í˜ì´ì§€ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

