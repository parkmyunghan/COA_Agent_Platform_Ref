# ui/components/chat_interface_v2.py
# -*- coding: utf-8 -*-
"""
ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ v2 (ì¸ìš© ëª¨ë“œ)
LLM ì‘ë‹µì— RAG ê²€ìƒ‰ ê²°ê³¼ ê·¼ê±°ë¥¼ í‘œì‹œ
"""
import streamlit as st
import json
from datetime import datetime
from ui.components.citation_panel import render_citation_panel, highlight_citations_in_text, render_citation_summary
from ui.components.user_friendly_errors import render_user_friendly_error


def render_chat_interface(orchestrator, selected_agent, agents_list, coa_type_filter=None):
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ v2 (ì¸ìš© ëª¨ë“œ)"""
    st.subheader("LLM ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© (ì¸ìš© ëª¨ë“œ)")
    
    # ëª¨ë¸ ì„ íƒ UI ì¶”ê°€ (í”„ë¡¬í”„íŠ¸ ì…ë ¥ì°½ ìœ„ì— ë°°ì¹˜)
    from ui.components.llm_model_selector import render_llm_model_selector
    selected_model_key = render_llm_model_selector(orchestrator.core.llm_manager, key_prefix="chat_")
    
    # ì „ì—­ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ëŒ€ì‹œë³´ë“œì™€ ë™ê¸°í™”)
    st.session_state["selected_llm_manager"] = selected_model_key
    
    st.divider()
    
    # ì¸ìš© ëª¨ë“œ ì„¤ëª…
    st.info("ì°¸ê³ : ì¸ìš© ëª¨ë“œ: LLM ì‘ë‹µì— ì°¸ê³  ë¬¸ì„œ ê·¼ê±° ë²ˆí˜¸ê°€ ìë™ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤.")
    
    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "messages_v2" not in st.session_state:
        st.session_state.messages_v2 = []
    
    if "citations_v2" not in st.session_state:
        st.session_state.citations_v2 = {}
    
    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    for msg in st.session_state.messages_v2:
        with st.chat_message(msg["role"]):
            # ì¸ìš© ë²ˆí˜¸ í•˜ì´ë¼ì´íŠ¸
            if msg["role"] == "assistant" and "citations" in msg:
                # ì¸ìš© ë²ˆí˜¸ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ í•˜ì´ë¼ì´íŠ¸
                highlighted_content = highlight_citations_in_text(msg["content"])
                st.markdown(highlighted_content, unsafe_allow_html=True)
            else:
                st.write(msg["content"])
            
            if "timestamp" in msg:
                st.caption(msg["timestamp"])
            
            # ê·¼ê±° í‘œì‹œ (ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ì¸ ê²½ìš°)
            if msg["role"] == "assistant" and "citations" in msg and msg["citations"]:
                with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ ê·¼ê±°", expanded=False):
                    render_citation_panel(msg["citations"], highlight_query=msg.get("query", ""))
            
            # ğŸ”¥ NEW: ì§„í–‰ ìƒí™© ë¡œê·¸ í‘œì‹œ (ì˜êµ¬ ë³´ê´€)
            if msg["role"] == "assistant" and "metadata" in msg and "progress_logs" in msg["metadata"]:
                logs = msg["metadata"]["progress_logs"]
                if logs:
                    with st.status("âœ… ë¶„ì„ ì™„ë£Œ (100%)", state="complete", expanded=False):
                        for log in logs:
                            st.write(log)
    
    # ì‚¬ìš©ì ì…ë ¥
    user_prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì êµ° ìœ„í˜‘ ìƒí™© ê·¼ê±° í¬í•¨ ìš”ì•½)")
    
    if user_prompt:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_msg = {
            "role": "user",
            "content": user_prompt,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        st.session_state.messages_v2.append(user_msg)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ
        with st.chat_message("user"):
            st.write(user_prompt)
            st.caption(user_msg["timestamp"])
        
        # ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.status("ì²˜ë¦¬ ì¤‘...", expanded=False) as status:
                try:
                    # ì§„í–‰ ìƒí™© ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ (ë©”ì‹œì§€ ë©”íƒ€ë°ì´í„°ì— ì €ì¥ ì˜ˆì •)
                    progress_logs = []
                    
                    # 1. RAG ê²€ìƒ‰ (ê·¼ê±° ë¬¸ì„œ ê²€ìƒ‰)
                    label = "ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘..."
                    status.update(label=label)
                    progress_logs.append(f"  - {label}")
                    
                    retrieved = []
                    if orchestrator.core.rag_manager.embedding_model is not None:
                        try:
                            retrieved = orchestrator.core.rag_manager.retrieve_with_context(
                                user_prompt, top_k=3
                            )
                        except Exception as e:
                            render_user_friendly_error(e, "RAG ê²€ìƒ‰")
                    
                    # 2. Agent ì‹¤í–‰ (ì„ íƒëœ ê²½ìš°)
                    agent_result = None
                    if selected_agent:
                        label = f"ì—ì´ì „íŠ¸ ë¶„ì„ ì¤‘: {selected_agent}"
                        status.update(label=label)
                        progress_logs.append(f"  - {label}")
                        
                        try:
                            agent_info = next(
                                (a for a in agents_list if a.get("name") == selected_agent),
                                None
                            )
                            if agent_info:
                                cls_path = agent_info.get("class")
                                if cls_path:
                                    AgentClass = orchestrator.load_agent_class(cls_path)
                                    agent = AgentClass(core=orchestrator.core)
                                    
                                    # ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜ ì •ì˜ (í¼ì„¼íŠ¸ ì§€ì›)
                                    def on_status_update(msg, progress=None):
                                        log_entry = f"  - {msg}"
                                        if progress is not None:
                                            log_entry = f"  - [{progress}%] {msg}"
                                            curr_label = f"ë¶„ì„ ì¤‘: {progress}% - {msg}"
                                        else:
                                            curr_label = f"ë¶„ì„ ì¤‘: {msg}"
                                        
                                        st.write(log_entry)
                                        status.update(label=curr_label)
                                        progress_logs.append(log_entry)

                                    # íŒ”ë€í‹°ì–´ ëª¨ë“œ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ì—¬ëŸ¬ í‚¤ í™•ì¸, ê¸°ë³¸ê°’ True)
                                    use_palantir_mode = (
                                        st.session_state.get("use_palantir_mode", True) or
                                        st.session_state.get("dashboard_use_palantir_mode", False) or
                                        st.session_state.get("agent_page_use_palantir_mode", False)
                                    )
                                    # RAG ê²€ìƒ‰ì€ í•­ìƒ í™œì„±í™” (íŒ”ë€í‹°ì–´ ëª¨ë“œì—ì„œ ê³¼ê±° ì„±ê³µë¥  ê³„ì‚° ë° LLM ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©)
                                    enable_rag_search = True
                                    
                                    # ì„ íƒí•œ ìœ„í˜‘ìƒí™© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                                    # ë ˆê±°ì‹œ í˜¸í™˜: demo_scenario_dataë„ í™•ì¸
                                    selected_situation_info = st.session_state.get("selected_situation_info") or st.session_state.get("demo_scenario_data")
                                    situation_id = None
                                    if selected_situation_info:
                                        # situation_id ìš°ì„ , ì—†ìœ¼ë©´ ìœ„í˜‘ID ì‚¬ìš©
                                        situation_id = selected_situation_info.get("situation_id") or selected_situation_info.get("ìœ„í˜‘ID")
                                    
                                    agent_result = agent.execute_reasoning(
                                        situation_id=situation_id,  # ì„ íƒí•œ ìœ„í˜‘ìƒí™©ì˜ situation_id ì „ë‹¬
                                        user_query=user_prompt,  # ì‚¬ìš©ì ì§ˆë¬¸ ì „ë‹¬
                                        selected_situation_info=selected_situation_info,  # âœ… ì¶”ê°€: ì„ íƒí•œ ìœ„í˜‘ìƒí™© ì •ë³´ ì§ì ‘ ì „ë‹¬
                                        use_palantir_mode=use_palantir_mode,
                                        enable_rag_search=enable_rag_search,
                                        coa_type_filter=coa_type_filter,  # âœ… ì¶”ê°€: ë°©ì±… ìœ í˜• í•„í„° ì „ë‹¬
                                        status_callback=on_status_update
                                    )
                                    
                                    # ... (ì¤‘ëµ - ì´í›„ í…ìŠ¤íŠ¸ êµ¬ì„± ë¡œì§)
                                    status.update(label="ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ (100%)", state="complete")
                                    progress_logs.append("  - ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ")
                                    
                                    # Agent ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€ (LLMì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ ì›ë³¸ ë°ì´í„° ì œê³µ)
                                    # agent_resultê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ selected_situation_info ì‚¬ìš©
                                    if agent_result or selected_situation_info:
                                        import json
                                        # Agent ê²°ê³¼ì—ì„œ situation_info ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ selected_situation_info ì‚¬ìš©)
                                        situation_info = agent_result.get("situation_info", {}) if agent_result else {}
                                        if not situation_info and selected_situation_info:
                                            situation_info = selected_situation_info
                                        
                                        recommendations = agent_result.get("recommendations", []) if agent_result else []
                                        
                                        # ìƒí™© ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ êµ¬ì„±
                                        # ... (ìƒëµëœ ê²½ìš° íˆ´ì—ì„œ ì›ë³¸ì„ ìœ ì§€í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì£¼ì˜í•´ì„œ ì‘ì„±)
                                        # ì—¬ê¸°ì„œëŠ” ì›ë³¸ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ í™œìš©í•˜ì—¬ context logicë§Œ status ë°”ê¹¥ìœ¼ë¡œ ëºŒ
                                        # ë˜ëŠ” spinner ë‚´ë¶€ì— ë‘ .
                                        status.update(label="LLM ë‹µë³€ ìƒì„± ì¤‘...")
                                        progress_logs.append("  - LLM ë‹µë³€ ìƒì„± ì¤‘...")
                                        if situation_info:
                                            situation_text = "=== ì„ íƒí•œ ìœ„í˜‘ìƒí™© ì •ë³´ ===\n"
                                            situation_text += f"ìœ„í˜‘ ID: {situation_info.get('ìœ„í˜‘ID', situation_info.get('ID', situation_info.get('situation_id', 'N/A')))}\n"
                                            # ìœ„í˜‘ ìœ í˜• ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œëª… ì§€ì›)
                                            threat_type = (situation_info.get('ìœ„í˜‘ìœ í˜•') or 
                                                          situation_info.get('threat_type') or 
                                                          'N/A')
                                            situation_text += f"ìœ„í˜‘ ìœ í˜•: {threat_type}\n"
                                            # ì‹¬ê°ë„ ë° ìœ„í˜‘ìˆ˜ì¤€ ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œëª… ì§€ì›)
                                            severity = (situation_info.get('ì‹¬ê°ë„') or 
                                                       situation_info.get('ìœ„í˜‘ìˆ˜ì¤€'))
                                            threat_level = situation_info.get('threat_level')
                                            
                                            if severity is None:
                                                # threat_levelì´ ìˆìœ¼ë©´ ë³€í™˜
                                                if threat_level is not None:
                                                    severity = int(float(threat_level) * 100)
                                            
                                            if threat_level is None:
                                                # severityê°€ ìˆìœ¼ë©´ threat_levelë¡œ ë³€í™˜
                                                if severity is not None:
                                                    try:
                                                        severity_float = float(severity)
                                                        threat_level = severity_float / 100.0 if severity_float > 1.0 else severity_float
                                                    except:
                                                        pass
                                            
                                            situation_text += f"ì‹¬ê°ë„: {severity if severity is not None else 'N/A'}\n"
                                            # ìœ„í˜‘ìˆ˜ì¤€ë„ ëª…ì‹œì ìœ¼ë¡œ í‘œì‹œ (ê°•ì¡°) - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•˜ì—¬ ê°•ì¡°
                                            if threat_level is not None:
                                                threat_level_pct = int(float(threat_level) * 100)
                                                if threat_level >= 0.95:
                                                    threat_level_desc = "ë§¤ìš° ë†’ìŒ (ìµœê³  ìœ„í˜‘)"
                                                    threat_level_warning = "âš ï¸âš ï¸âš ï¸ ë§¤ìš° ë†’ì€ ìœ„í˜‘: ê°•ë ¥í•œ ë°©ì–´ ë°©ì±…(Main_Defense) í•„ìˆ˜"
                                                elif threat_level > 0.8:
                                                    threat_level_desc = "ë†’ìŒ"
                                                    threat_level_warning = "âš ï¸âš ï¸ ë†’ì€ ìœ„í˜‘: ê°•ë ¥í•œ ë°©ì–´ ë°©ì±…(Main_Defense) ê¶Œì¥"
                                                elif threat_level > 0.5:
                                                    threat_level_desc = "ë³´í†µ"
                                                    threat_level_warning = "â„¹ï¸ ë³´í†µ ìœ„í˜‘: ì¤‘ê°„ ë°©ì–´ ë°©ì±…(Moderate_Defense) ì í•©"
                                                elif threat_level > 0.3:
                                                    threat_level_desc = "ë‚®ìŒ"
                                                    threat_level_warning = "â„¹ï¸ ë‚®ì€ ìœ„í˜‘: ìµœì†Œ ë°©ì–´ ë°©ì±…(Minimal_Defense) ì í•©"
                                                else:
                                                    threat_level_desc = "ë§¤ìš° ë‚®ìŒ"
                                                    threat_level_warning = "â„¹ï¸ ë§¤ìš° ë‚®ì€ ìœ„í˜‘: ìµœì†Œ ë°©ì–´ ë°©ì±…(Minimal_Defense) ì¶©ë¶„"
                                                # ìœ„í˜‘ìˆ˜ì¤€ì„ ì—¬ëŸ¬ ë²ˆ ê°•ì¡°
                                                situation_text += f"\nğŸ”´ **ìœ„í˜‘ìˆ˜ì¤€: {threat_level_pct}%** ({threat_level_desc})\n"
                                                situation_text += f"ğŸ”´ **ìœ„í˜‘ìˆ˜ì¤€: {threat_level_pct}%** ({threat_level_desc})\n"
                                                situation_text += f"{threat_level_warning}\n"
                                                situation_text += f"\n**ì¤‘ìš”**: ìœ„í˜‘ìˆ˜ì¤€ì€ {threat_level_pct}%ì…ë‹ˆë‹¤. ì´ ê°’ì„ ì •í™•íˆ ë°˜ì˜í•˜ì„¸ìš”.\n"
                                            location = situation_info.get('ë°œìƒì¥ì†Œ', situation_info.get('ì¥ì†Œ', 'N/A'))
                                            if location and location != 'N/A':
                                                situation_text += f"ë°œìƒ ì¥ì†Œ: {location}\n"
                                            if situation_info.get('íƒì§€ì‹œê°'):
                                                situation_text += f"íƒì§€ ì‹œê°: {situation_info.get('íƒì§€ì‹œê°')}\n"
                                            if situation_info.get('ê·¼ê±°'):
                                                situation_text += f"ê·¼ê±°: {situation_info.get('ê·¼ê±°')}\n"
                                            situation_text += "\n"
                                        
                                        # ì¶”ì²œ ë°©ì±…ì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ êµ¬ì„±
                                        recommendations_text = ""
                                        if recommendations:
                                            recommendations_text = "=== ì¶”ì²œ ë°©ì±… (ì ìˆ˜ ìˆœìœ„) ===\n"
                                            for i, rec in enumerate(recommendations[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                                                coa_name = rec.get('coa_name', 'N/A')
                                                score = rec.get('score', 0)
                                                reason = rec.get('reason', 'N/A')
                                                score_breakdown = rec.get('score_breakdown', {})
                                                
                                                # ë°©ì±… ìœ í˜• íŒë‹¨
                                                coa_type = ""
                                                if 'main' in coa_name.lower() or 'ì£¼ìš”' in coa_name.lower() or 'ê°•ë ¥' in coa_name.lower():
                                                    coa_type = " [ê°•ë ¥í•œ ë°©ì±…]"
                                                elif 'moderate' in coa_name.lower() or 'ì¤‘ê°„' in coa_name.lower():
                                                    coa_type = " [ì¤‘ê°„ ë°©ì±…]"
                                                elif 'minimal' in coa_name.lower() or 'ìµœì†Œ' in coa_name.lower():
                                                    coa_type = " [ìµœì†Œ ë°©ì±…]"
                                                
                                                recommendations_text += f"{i}. {coa_name}{coa_type} (ì¢…í•© ì ìˆ˜: {score:.3f})\n"
                                                if score_breakdown:
                                                    threat_score = score_breakdown.get('threat', 0)
                                                    recommendations_text += f"   - ìœ„í˜‘ ì ìˆ˜: {threat_score:.3f}\n"
                                                if reason and reason != 'N/A':
                                                    recommendations_text += f"   - ì¶”ì²œ ì‚¬ìœ : {reason}\n"
                                            recommendations_text += "\n"
                                        
                                        # ì „ì²´ Agent ê²°ê³¼ë¥¼ JSONìœ¼ë¡œë„ í¬í•¨ (ìƒì„¸ ì •ë³´ìš©)
                                        agent_data = {
                                            "situation_info": situation_info,
                                            "recommendations": recommendations,
                                            "status": agent_result.get("status", ""),
                                            "situation_id": agent_result.get("situation_id")
                                        }
                                        
                                        # êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ + JSON í˜•íƒœë¡œ ì „ë‹¬
                                        # ìœ„í˜‘ìˆ˜ì¤€ì„ ëª…í™•í•˜ê²Œ ê°•ì¡°
                                        threat_level_emphasis = ""
                                        if threat_level is not None:
                                            threat_level_pct = int(float(threat_level) * 100)
                                            threat_level_emphasis = f"\n\nğŸ”´ **ì¤‘ìš”**: í˜„ì¬ ìœ„í˜‘ìˆ˜ì¤€ì€ {threat_level_pct}%ì…ë‹ˆë‹¤. "
                                            if threat_level >= 0.95:
                                                threat_level_emphasis += "ë§¤ìš° ë†’ì€ ìœ„í˜‘ì´ë¯€ë¡œ ë°˜ë“œì‹œ Main_Defense ë°©ì±…ì„ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤."
                                            elif threat_level > 0.8:
                                                threat_level_emphasis += "ë†’ì€ ìœ„í˜‘ì´ë¯€ë¡œ Main_Defense ë°©ì±…ì„ ìš°ì„  ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤."
                                            elif threat_level > 0.5:
                                                threat_level_emphasis += "ë³´í†µ ìœ„í˜‘ì´ë¯€ë¡œ Moderate_Defense ë°©ì±…ì´ ì í•©í•©ë‹ˆë‹¤."
                                            else:
                                                threat_level_emphasis += "ë‚®ì€ ìœ„í˜‘ì´ë¯€ë¡œ Minimal_Defense ë°©ì±…ìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
                                        
                                        agent_result_text = f"""[Agent ì‹¤í–‰ ê²°ê³¼ ë°ì´í„°]

{situation_text}{threat_level_emphasis}{recommendations_text}
[ìƒì„¸ ë°ì´í„° (JSON)]
{json.dumps(agent_data, ensure_ascii=False, indent=2)}"""
                                        
                                        retrieved.append({
                                            "doc_id": -1,
                                            "text": agent_result_text,
                                            "score": 1.0,
                                            "index": -1,
                                            "metadata": {"source": "agent", "agent_result": agent_result}
                                        })
                        except Exception as e:
                            render_user_friendly_error(e, "Agent ì‹¤í–‰")
                    
                    # 3. LLM ì‘ë‹µ ìƒì„± (ì¸ìš© í¬í•¨)
                    llm_reply = None
                    if orchestrator.core.llm_manager.is_available():
                        try:
                            if retrieved:
                                # ì¸ìš© ëª¨ë“œë¡œ ìƒì„±
                                llm_reply = orchestrator.core.llm_manager.generate_with_citations(
                                    user_prompt, retrieved, max_tokens=512
                                )
                            else:
                                # ê·¼ê±° ì—†ì´ ê¸°ë³¸ ìƒì„±
                                llm_reply = orchestrator.core.llm_manager.generate(
                                    user_prompt, max_tokens=512
                                )
                        except Exception as e:
                            render_user_friendly_error(e, "LLM ì‘ë‹µ ìƒì„±")
                            llm_reply = "[LLM ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Agent ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.]"
                    else:
                        # LLMì´ ì—†ìœ¼ë©´ Agent ê²°ê³¼ë§Œ í‘œì‹œ
                        if agent_result:
                            llm_reply = agent_result.get("summary", "Agent ì‹¤í–‰ ì™„ë£Œ")
                        else:
                            llm_reply = "[LLM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.]"
                    
                    # 4. ì‘ë‹µ í‘œì‹œ (ì¸ìš© ë²ˆí˜¸ í•˜ì´ë¼ì´íŠ¸)
                    highlighted_reply = highlight_citations_in_text(llm_reply)
                    st.markdown(highlighted_reply, unsafe_allow_html=True)
                    
                    # 5. ê·¼ê±° íŒ¨ë„ í‘œì‹œ
                    if retrieved:
                        st.divider()
                        render_citation_panel(retrieved, highlight_query=user_prompt)
                        
                        # ê·¼ê±° ìš”ì•½ (ê°„ë‹¨ ë²„ì „)
                        with st.expander("ğŸ“‹ ê·¼ê±° ìš”ì•½", expanded=False):
                            render_citation_summary(retrieved)
                    
                    # 6. ìƒì„¸ ì •ë³´
                    with st.expander("ğŸ“‹ ìƒì„¸ ì •ë³´", expanded=False):
                        if agent_result:
                            st.markdown("**Agent ì‹¤í–‰ ê²°ê³¼:**")
                            st.json(agent_result)
                        
                        st.markdown("**RAG ê²€ìƒ‰ ê²°ê³¼:**")
                        st.json({
                            "query": user_prompt,
                            "results_count": len(retrieved),
                            "results": retrieved
                        })
                    
                    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
                    assistant_msg = {
                        "role": "assistant",
                        "content": llm_reply,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "citations": retrieved,
                        "query": user_prompt,
                        "metadata": {
                            "agent_result": agent_result if agent_result else None,
                            "progress_logs": progress_logs # ğŸ”¥ ì¶”ê°€: ì§„í–‰ ìƒí™© ë¡œê·¸ ì €ì¥
                        }
                    }
                    st.session_state.messages_v2.append(assistant_msg)
                    
                    # ì¸ìš© ì •ë³´ ì €ì¥
                    st.session_state.citations_v2[len(st.session_state.messages_v2) - 1] = retrieved
                    
                    # LLM-Agent í˜‘ë ¥ ì •ë³´ í‘œì‹œ (ìƒˆë¡œ ì¶”ê°€)
                    if agent_result:
                        llm_collab = agent_result.get("llm_collaboration", {})
                        if llm_collab:
                            st.divider()
                            with st.expander("ğŸ¤ LLM-Agent í˜‘ë ¥ ì •ë³´", expanded=False):
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.write("**ìƒí™© ë¶„ì„**:", "âœ… ì‚¬ìš©" if llm_collab.get("situation_analysis_used") else "âŒ ë¯¸ì‚¬ìš©")
                                    st.write("**ë°©ì±… í‰ê°€**:", "âœ… ì‚¬ìš©" if llm_collab.get("strategy_evaluation_used") else "âŒ ë¯¸ì‚¬ìš©")
                                with col2:
                                    insights = llm_collab.get("llm_insights", {})
                                    st.write("**ì£¼ìš” ê³ ë ¤ì‚¬í•­**:", len(insights.get("key_factors", [])))
                                    st.write("**ì œì•½ì¡°ê±´**:", len(insights.get("constraints", [])))
                    
                except Exception as e:
                    render_user_friendly_error(e, "ì±„íŒ… ì¸í„°í˜ì´ìŠ¤")
                    error_msg = "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ í•´ê²° ë°©ë²•ì„ ì°¸ê³ í•˜ì„¸ìš”."
                    st.session_state.messages_v2.append({
                        "role": "assistant",
                        "content": error_msg,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    })
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    if st.session_state.messages_v2:
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ"):
                st.session_state.messages_v2 = []
                st.session_state.citations_v2 = {}
                st.rerun()
        with col2:
            st.caption(f"ì´ {len(st.session_state.messages_v2)}ê°œ ë©”ì‹œì§€")
        with col3:
            citation_count = sum(len(c) for c in st.session_state.citations_v2.values())
            st.caption(f"ì´ {citation_count}ê°œ ê·¼ê±° ë¬¸ì„œ")

