# ui/components/relationship_quality_validator.py
# -*- coding: utf-8 -*-
"""
ê´€ê³„ í’ˆì§ˆ ê²€ì¦ ì»´í¬ë„ŒíŠ¸
AIê°€ ìë™ ìƒì„±í•œ ê´€ê³„ì˜ ì ì •ì„±ì„ ê²€ì¦í•˜ëŠ” ë„êµ¬
"""
import streamlit as st
import pandas as pd
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
import json
from pathlib import Path


def render_relationship_quality_validator(orchestrator, show_title=True):
    """
    ê´€ê³„ í’ˆì§ˆ ê²€ì¦ ëŒ€ì‹œë³´ë“œ
    
    Args:
        orchestrator: Orchestrator ì¸ìŠ¤í„´ìŠ¤
        show_title: ì œëª© í‘œì‹œ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    """
    if show_title:
        st.markdown("### ğŸ” ê´€ê³„ í’ˆì§ˆ ê²€ì¦ (Relationship Quality Validation)")
    st.info("ğŸ’¡ **AIê°€ ìë™ ìƒì„±í•œ ê´€ê³„ì˜ ì ì •ì„±ì„ ê²€ì¦**í•˜ê³ , ì´ìƒ íŒ¨í„´ì„ íƒì§€í•©ë‹ˆë‹¤.")
    
    ontology_manager = orchestrator.core.enhanced_ontology_manager
    if not ontology_manager or not ontology_manager.graph:
        st.warning("ì˜¨í†¨ë¡œì§€ ê·¸ë˜í”„ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì˜¨í†¨ë¡œì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return
    
    graph = ontology_manager.graph
    ns = ontology_manager.ns
    
    # 1. ì „ì²´ í†µê³„
    st.markdown("#### ğŸ“Š ì „ì²´ ê´€ê³„ í†µê³„")
    quality_report = _analyze_relationship_quality(graph, ns, ontology_manager)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì „ì²´ íŠœí”Œ ìˆ˜", f"{quality_report['total_triples']:,}")
    with col2:
        st.metric("ê´€ê³„ ìœ í˜• ìˆ˜", quality_report['relation_type_count'])
    with col3:
        st.metric("í‰ê·  ê´€ê³„ ë°€ë„", f"{quality_report['avg_relationship_density']:.2f}")
    with col4:
        anomaly_score = quality_report.get('anomaly_score', 0)
        st.metric("ì´ìƒ íŒ¨í„´ ì ìˆ˜", f"{anomaly_score:.1f}%", 
                 delta=f"{'ì •ìƒ' if anomaly_score < 30 else 'ì£¼ì˜' if anomaly_score < 60 else 'ìœ„í—˜'}")
    
    # 2. ê´€ê³„ ìœ í˜•ë³„ ë¶„ì„
    st.divider()
    st.markdown("#### ğŸ“ˆ ê´€ê³„ ìœ í˜•ë³„ ë¶„ì„")
    
    relation_stats = quality_report.get('relation_type_stats', [])
    if relation_stats:
        # í…Œì´ë¸”ë¡œ í‘œì‹œ
        df_stats = pd.DataFrame(relation_stats)
        df_stats = df_stats.sort_values('count', ascending=False)
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.dataframe(
                df_stats[['relation_type', 'count', 'percentage', 'status']],
                use_container_width=True,
                hide_index=True
            )
        with col2:
            # ì´ìƒ íŒ¨í„´ í•˜ì´ë¼ì´íŠ¸
            anomalies = [r for r in relation_stats if r.get('is_anomaly', False)]
            if anomalies:
                st.warning(f"âš ï¸ **{len(anomalies)}ê°œ ì´ìƒ íŒ¨í„´ ë°œê²¬**")
                for anomaly in anomalies[:5]:
                    st.markdown(f"- `{anomaly['relation_type']}`: {anomaly['count']:,}ê°œ")
            else:
                st.success("âœ… ì´ìƒ íŒ¨í„´ ì—†ìŒ")
    
    # 3. í…Œì´ë¸”ë³„ ê´€ê³„ ë°€ë„ ë¶„ì„
    st.divider()
    st.markdown("#### ğŸ—‚ï¸ í…Œì´ë¸”ë³„ ê´€ê³„ ë°€ë„ ë¶„ì„")
    
    table_density = quality_report.get('table_density', {})
    if table_density:
        df_density = pd.DataFrame([
            {
                "í…Œì´ë¸”": table,
                "ê´€ê³„ ìˆ˜": stats['relation_count'],
                "í‰ê·  ë°€ë„": f"{stats['avg_density']:.2f}",
                "ìƒíƒœ": stats['status']
            }
            for table, stats in table_density.items()
        ])
        df_density = df_density.sort_values('ê´€ê³„ ìˆ˜', ascending=False)
        
        st.dataframe(df_density, use_container_width=True, hide_index=True)
        
        # ì´ìƒ ë°€ë„ í…Œì´ë¸” í•˜ì´ë¼ì´íŠ¸
        high_density_tables = [
            (table, stats) 
            for table, stats in table_density.items() 
            if stats.get('is_anomaly', False)
        ]
        if high_density_tables:
            st.warning("âš ï¸ **ì´ìƒì ìœ¼ë¡œ ë†’ì€ ê´€ê³„ ë°€ë„ë¥¼ ê°€ì§„ í…Œì´ë¸”:**")
            for table, stats in high_density_tables[:5]:
                st.markdown(f"- `{table}`: {stats['relation_count']:,}ê°œ ê´€ê³„ (í‰ê·  ëŒ€ë¹„ {stats['density_ratio']:.1f}ë°°)")
    
    # 4. ê´€ê³„ íŒ¨í„´ ì‹œê°í™”
    st.divider()
    st.markdown("#### ğŸ“Š ê´€ê³„ íŒ¨í„´ ì‹œê°í™”")
    
    viz_mode = st.radio(
        "ì‹œê°í™” ëª¨ë“œ",
        ["ê´€ê³„ ìœ í˜•ë³„ ë¶„í¬", "í…Œì´ë¸”ë³„ ê´€ê³„ ë°€ë„", "ì´ìƒ íŒ¨í„´ í•˜ì´ë¼ì´íŠ¸"],
        horizontal=True
    )
    
    if viz_mode == "ê´€ê³„ ìœ í˜•ë³„ ë¶„í¬":
        _render_relation_type_distribution(relation_stats)
    elif viz_mode == "í…Œì´ë¸”ë³„ ê´€ê³„ ë°€ë„":
        _render_table_density_chart(table_density)
    else:
        _render_anomaly_highlight(quality_report)
    
    # 5. ê²€ì¦ ê¶Œì¥ì‚¬í•­
    st.divider()
    st.markdown("#### ğŸ’¡ ê²€ì¦ ê¶Œì¥ì‚¬í•­")
    
    recommendations = _generate_recommendations(quality_report)
    for i, rec in enumerate(recommendations, 1):
        with st.expander(f"{i}. {rec['title']}", expanded=(i == 1)):
            st.markdown(rec['description'])
            if rec.get('actions'):
                st.markdown("**ê¶Œì¥ ì¡°ì¹˜:**")
                for action in rec['actions']:
                    st.markdown(f"- {action}")


def _analyze_relationship_quality(graph, ns, ontology_manager) -> Dict:
    """ê´€ê³„ í’ˆì§ˆ ë¶„ì„"""
    # ì „ì²´ íŠœí”Œ ìˆ˜
    all_triples = list(graph.triples((None, None, None)))
    total_triples = len(all_triples)
    
    # ê´€ê³„ ìœ í˜•ë³„ í†µê³„
    relation_type_counts = defaultdict(int)
    relation_type_details = defaultdict(list)
    
    for s, p, o in all_triples:
        # ì˜¨í†¨ë¡œì§€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ê´€ê³„ë§Œ ì¹´ìš´íŠ¸ (rdf:type ì œì™¸)
        if str(p).startswith(str(ns)) and str(p) != str(ns.type):
            relation_name = str(p).replace(str(ns), "")
            relation_type_counts[relation_name] += 1
            relation_type_details[relation_name].append((str(s), str(o)))
    
    # í‰ê·  ê´€ê³„ ë°€ë„ ê³„ì‚°
    avg_count = sum(relation_type_counts.values()) / len(relation_type_counts) if relation_type_counts else 0
    std_count = _calculate_std([v for v in relation_type_counts.values()]) if relation_type_counts else 0
    
    # ì´ìƒ íŒ¨í„´ íƒì§€ (Z-score ê¸°ë°˜)
    relation_type_stats = []
    for rel_type, count in relation_type_counts.items():
        z_score = (count - avg_count) / std_count if std_count > 0 else 0
        is_anomaly = abs(z_score) > 2.0  # 2 í‘œì¤€í¸ì°¨ ì´ìƒ
        
        relation_type_stats.append({
            "relation_type": rel_type,
            "count": count,
            "percentage": (count / total_triples * 100) if total_triples > 0 else 0,
            "z_score": z_score,
            "is_anomaly": is_anomaly,
            "status": "âš ï¸ ì´ìƒ" if is_anomaly else "âœ… ì •ìƒ"
        })
    
    # í…Œì´ë¸”ë³„ ê´€ê³„ ë°€ë„ ë¶„ì„
    table_density = _analyze_table_density(graph, ns, ontology_manager)
    
    # ì´ìƒ ì ìˆ˜ ê³„ì‚° (0-100, ë†’ì„ìˆ˜ë¡ ì´ìƒ)
    anomaly_count = sum(1 for r in relation_type_stats if r['is_anomaly'])
    anomaly_score = (anomaly_count / len(relation_type_stats) * 100) if relation_type_stats else 0
    
    return {
        "total_triples": total_triples,
        "relation_type_count": len(relation_type_counts),
        "avg_relationship_density": avg_count,
        "relation_type_stats": relation_type_stats,
        "table_density": table_density,
        "anomaly_score": anomaly_score,
        "anomaly_count": anomaly_count
    }


def _analyze_table_density(graph, ns, ontology_manager) -> Dict:
    """í…Œì´ë¸”ë³„ ê´€ê³„ ë°€ë„ ë¶„ì„"""
    schema_registry = ontology_manager.schema_registry if ontology_manager else {}
    
    # í…Œì´ë¸”ë³„ ê´€ê³„ ìˆ˜ ì§‘ê³„
    table_relations = defaultdict(int)
    
    for s, p, o in graph.triples((None, None, None)):
        if str(p).startswith(str(ns)) and str(p) != str(ns.type):
            # ì£¼ì²´ê°€ ì–´ëŠ í…Œì´ë¸”ì— ì†í•˜ëŠ”ì§€ ì¶”ì •
            s_str = str(s)
            for table_name in schema_registry.keys():
                if table_name in s_str or any(col in s_str for col in schema_registry.get(table_name, {}).get('columns', {}).keys()):
                    table_relations[table_name] += 1
                    break
    
    # í‰ê·  ë°€ë„ ê³„ì‚°
    avg_density = sum(table_relations.values()) / len(table_relations) if table_relations else 0
    std_density = _calculate_std([v for v in table_relations.values()]) if table_relations else 0
    
    # í…Œì´ë¸”ë³„ ë°€ë„ ë¶„ì„
    result = {}
    for table, count in table_relations.items():
        z_score = (count - avg_density) / std_density if std_density > 0 else 0
        is_anomaly = abs(z_score) > 2.0
        
        result[table] = {
            "relation_count": count,
            "avg_density": avg_density,
            "z_score": z_score,
            "is_anomaly": is_anomaly,
            "density_ratio": count / avg_density if avg_density > 0 else 0,
            "status": "âš ï¸ ì´ìƒ" if is_anomaly else "âœ… ì •ìƒ"
        }
    
    return result


def _calculate_std(values: List[float]) -> float:
    """í‘œì¤€í¸ì°¨ ê³„ì‚°"""
    if not values:
        return 0.0
    mean = sum(values) / len(values)
    variance = sum((x - mean) ** 2 for x in values) / len(values)
    return variance ** 0.5


def _render_relation_type_distribution(relation_stats: List[Dict]):
    """ê´€ê³„ ìœ í˜•ë³„ ë¶„í¬ ì°¨íŠ¸"""
    if not relation_stats:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    df = pd.DataFrame(relation_stats)
    df = df.sort_values('count', ascending=False).head(20)
    
    st.bar_chart(df.set_index('relation_type')['count'])


def _render_table_density_chart(table_density: Dict):
    """í…Œì´ë¸”ë³„ ê´€ê³„ ë°€ë„ ì°¨íŠ¸"""
    if not table_density:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    df = pd.DataFrame([
        {"í…Œì´ë¸”": table, "ê´€ê³„ ìˆ˜": stats['relation_count']}
        for table, stats in table_density.items()
    ])
    df = df.sort_values('ê´€ê³„ ìˆ˜', ascending=False)
    
    st.bar_chart(df.set_index('í…Œì´ë¸”')['ê´€ê³„ ìˆ˜'])


def _render_anomaly_highlight(quality_report: Dict):
    """ì´ìƒ íŒ¨í„´ í•˜ì´ë¼ì´íŠ¸"""
    anomalies = [
        r for r in quality_report.get('relation_type_stats', [])
        if r.get('is_anomaly', False)
    ]
    
    if not anomalies:
        st.success("âœ… ì´ìƒ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    st.warning(f"âš ï¸ **{len(anomalies)}ê°œ ì´ìƒ íŒ¨í„´ ë°œê²¬**")
    
    for anomaly in anomalies[:10]:
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.markdown(f"**{anomaly['relation_type']}**")
        with col2:
            st.metric("ê°œìˆ˜", f"{anomaly['count']:,}")
        with col3:
            st.metric("Z-score", f"{anomaly['z_score']:.2f}")


def _generate_recommendations(quality_report: Dict) -> List[Dict]:
    """ê²€ì¦ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    anomaly_score = quality_report.get('anomaly_score', 0)
    anomaly_count = quality_report.get('anomaly_count', 0)
    
    if anomaly_score > 60:
        recommendations.append({
            "title": "ë†’ì€ ì´ìƒ íŒ¨í„´ ë¹„ìœ¨",
            "description": f"ì „ì²´ ê´€ê³„ ìœ í˜•ì˜ {anomaly_score:.1f}%ì—ì„œ ì´ìƒ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ê³„ ìƒì„± ê·œì¹™ì„ ì¬ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.",
            "actions": [
                "ì´ìƒ íŒ¨í„´ì´ ë§ì€ ê´€ê³„ ìœ í˜•ì˜ ìƒì„± ê·œì¹™ í™•ì¸",
                "ê´€ê³„ ìƒì„± ì„ê³„ê°’ ì¡°ì • ê²€í† ",
                "ìˆ˜ë™ ê²€ì¦ ëŒ€ìƒ ê´€ê³„ ëª©ë¡ ì‘ì„±"
            ]
        })
    
    if anomaly_count > 0:
        recommendations.append({
            "title": "ì´ìƒ ê´€ê³„ ìœ í˜• ê²€í† ",
            "description": f"{anomaly_count}ê°œ ê´€ê³„ ìœ í˜•ì—ì„œ ì´ìƒ íŒ¨í„´ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ìœ í˜•ë³„ë¡œ ê´€ê³„ ìˆ˜ê°€ ì ì •í•œì§€ í™•ì¸í•˜ì„¸ìš”.",
            "actions": [
                "ì´ìƒ íŒ¨í„´ ëª©ë¡ì—ì„œ ê° ê´€ê³„ ìœ í˜• í´ë¦­í•˜ì—¬ ìƒì„¸ í™•ì¸",
                "ê´€ê³„ ìƒì„± ë¡œê·¸ í™•ì¸",
                "ê´€ê³„ ë§¤í•‘ ê·œì¹™ ê²€í† "
            ]
        })
    
    total_triples = quality_report.get('total_triples', 0)
    if total_triples > 100000:
        recommendations.append({
            "title": "ëŒ€ëŸ‰ì˜ íŠœí”Œ ìƒì„±",
            "description": f"ì´ {total_triples:,}ê°œì˜ íŠœí”Œì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ê³„ ìƒì„± ê·œì¹™ì´ ë„ˆë¬´ ê´€ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "actions": [
                "ê´€ê³„ ìƒì„± ê·œì¹™ì˜ í•„í„°ë§ ì¡°ê±´ ê°•í™” ê²€í† ",
                "ë¶ˆí•„ìš”í•œ ê´€ê³„ ì œê±° ê·œì¹™ ì¶”ê°€",
                "ê´€ê³„ í’ˆì§ˆ ì„ê³„ê°’ ì„¤ì •"
            ]
        })
    
    if not recommendations:
        recommendations.append({
            "title": "ê´€ê³„ í’ˆì§ˆ ì–‘í˜¸",
            "description": "í˜„ì¬ ê´€ê³„ í’ˆì§ˆì´ ì–‘í˜¸í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•˜ì„¸ìš”.",
            "actions": [
                "ì£¼ê¸°ì ì¸ ê´€ê³„ í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰",
                "ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€ ì‹œ ê´€ê³„ í’ˆì§ˆ í™•ì¸"
            ]
        })
    
    return recommendations

