# LLM 기반 방책 선정사유 생성 성능 최적화 분석

## 1. 로그 분석 결과

### 1.1 전체 실행 시간 분석
- **시작 시간**: 2026-01-23 17:09:58
- **정황보고 생성 시작**: 17:12:20
- **방책 분석 시작**: 17:12:26
- **LLM 선정사유 생성 시작**: 17:12:41
- **최종 완료**: 17:13:42

### 1.2 단계별 시간 소요
1. **시스템 초기화**: ~42초 (17:09:58 ~ 17:10:40)
   - OWL-RL 추론: 13.99초
   - LLM 초기화: ~3초
   - RAG 모델 로드: ~10초

2. **정황보고 생성**: ~2초 (17:12:20 ~ 17:12:22)
   - LLM 호출: 1회

3. **방책 분석 및 평가**: ~9초 (17:12:26 ~ 17:12:35)
   - COA 점수 계산: 약 70개 방책

4. **LLM 기반 선정사유 생성**: **~45초** (17:12:41 ~ 17:13:26) 🔴 **최대 병목**
   - 총 **77회** LLM 호출
   - 모든 후보 방책에 대해 선정사유 생성
   - 순차 처리로 인한 지연

5. **최종 상위 방책 선정사유**: ~12초 (17:13:29 ~ 17:13:41)
   - 상위 3개 방책에 대한 추가 선정사유 생성

6. **시각화 데이터 생성**: ~1초 (17:13:41 ~ 17:13:42)

**총 방책추천 시간**: 약 **82초** (17:12:20 ~ 17:13:42)
- **LLM 선정사유 생성이 전체 시간의 약 55% 차지** (45초 / 82초)

## 2. 발견된 성능 병목

### 2.1 🔴 심각: 불필요한 LLM 호출

**문제점**:
- `_recommend_by_type()` 메서드에서 **모든 후보 방책(약 70개)**에 대해 선정사유를 생성
- 최종 상위 3개만 사용되는데 불필요한 LLM 호출 발생
- 순차 처리로 인해 각 호출마다 약 0.5-1초 소요

**코드 위치**:
- `agents/defense_coa_agent/logic_defense_enhanced.py:956, 959`
  ```python
  strategy['추천사유'] = self._generate_recommendation_reason(strategy, situation_info)
  detailed_reason = self._generate_recommendation_reason(strategy, situation_info)
  ```

**영향**:
- 약 70개 × 0.6초 = **42초** 불필요한 LLM 호출 시간
- API 비용 증가
- 응답 시간 지연

### 2.2 중복 선정사유 생성

**문제점**:
- `_recommend_by_type()`에서 선정사유 생성
- `execute_reasoning()`에서 최종 상위 방책에 대해 다시 선정사유 생성
- 동일한 방책에 대해 2번 생성되는 경우 발생

### 2.3 순차 처리

**문제점**:
- 모든 LLM 호출이 순차적으로 실행됨
- 병렬 처리 시 약 10-15초로 단축 가능

## 3. 개선 방안

### 3.1 즉시 적용 가능한 개선 (우선순위: 높음)

#### 방안 1: 최종 상위 방책에만 선정사유 생성

**목적**:
- 불필요한 LLM 호출 제거

**구현**:
1. `_recommend_by_type()`에서 선정사유 생성 제거
2. `execute_reasoning()`에서 최종 상위 `top_k`개에만 생성 (이미 구현됨)

**예상 효과**:
- LLM 호출: 77회 → **3회** (약 96% 감소)
- 시간 단축: 45초 → **2-3초** (약 93% 개선)
- 전체 시간: 82초 → **40초** (약 51% 개선)

**코드 수정 위치**:
- `agents/defense_coa_agent/logic_defense_enhanced.py:956, 959` 주석 처리 또는 제거

#### 방안 2: 병렬 처리 (asyncio)

**목적**:
- 상위 3개 방책의 선정사유를 병렬로 생성

**구현**:
- `asyncio.gather()` 또는 `ThreadPoolExecutor` 사용
- LLM 호출을 비동기로 실행

**예상 효과**:
- 순차 처리: 3회 × 1초 = 3초
- 병렬 처리: **1-1.5초** (약 50-66% 개선)

**주의사항**:
- LLM API의 동시 요청 제한 확인 필요
- Rate limiting 고려

### 3.2 중기 개선 방안 (우선순위: 중간)

#### 방안 3: 캐싱

**목적**:
- 동일한 COA + 상황 조합에 대해 선정사유 재사용

**구현**:
- `(coa_id, threat_type, threat_level, location)` 조합을 키로 캐싱
- 메모리 캐시 또는 Redis 사용

**예상 효과**:
- 반복 요청 시 LLM 호출 제거
- 추가적인 1-2초 단축 가능

#### 방안 4: 템플릿 기반 생성 (선택적)

**목적**:
- LLM 호출 없이 규칙 기반으로 선정사유 생성

**구현**:
- 점수 breakdown과 온톨로지 trace를 기반으로 템플릿 생성
- LLM 실패 시 fallback으로 사용 (이미 구현됨)

**예상 효과**:
- LLM 비용 절감
- 응답 시간 단축 (LLM 호출 시간 제거)

### 3.3 장기 개선 방안 (우선순위: 낮음)

#### 방안 5: 배치 LLM 호출

**목적**:
- 여러 방책의 선정사유를 하나의 프롬프트로 생성

**구현**:
- 상위 3개 방책 정보를 하나의 프롬프트에 포함
- LLM이 3개의 선정사유를 한 번에 생성

**예상 효과**:
- LLM 호출: 3회 → **1회**
- 시간 단축: 3초 → **1-1.5초**

**주의사항**:
- 프롬프트 길이 증가로 인한 토큰 비용 증가 가능
- 응답 품질 검증 필요

## 4. 권장 구현 순서

1. ✅ **즉시**: 방안 1 구현 (`_recommend_by_type`에서 선정사유 생성 제거)
2. ✅ **즉시**: 방안 2 구현 (병렬 처리)
3. ⏳ **중기**: 방안 3 (캐싱) 검토
4. ⏳ **장기**: 방안 4 (템플릿 기반) 또는 방안 5 (배치 호출) 검토

## 5. 예상 성능 개선 효과

### 현재 상태
- 전체 시간: **82초**
- LLM 선정사유 생성: **45초** (77회 호출)
- 최종 상위 방책 선정사유: **12초** (3회 호출)

### 개선 후 (방안 1 적용)
- 전체 시간: **40초** (약 51% 개선)
- LLM 선정사유 생성: **0초** (제거)
- 최종 상위 방책 선정사유: **3초** (3회 호출)

### 개선 후 (방안 1 + 방안 2 적용)
- 전체 시간: **38초** (약 54% 개선)
- LLM 선정사유 생성: **0초**
- 최종 상위 방책 선정사유: **1-1.5초** (병렬 처리)

### 개선 후 (방안 1 + 방안 2 + 방안 3 적용)
- 전체 시간: **36-37초** (약 55% 개선)
- 반복 요청 시 추가 단축 가능

## 6. 구현 체크리스트

- [x] `_recommend_by_type()`에서 선정사유 생성 코드 제거
- [x] `execute_reasoning()`에서만 최종 상위 방책에 대해 선정사유 생성 확인
- [x] 병렬 처리 구현 (ThreadPoolExecutor, 최대 3개 동시 처리)
- [x] 결과 정렬 로직 추가 (점수 순)
- [ ] LLM API 동시 요청 제한 확인 및 테스트
- [ ] 성능 테스트 및 시간 측정
- [ ] 문서 업데이트

## 7. 참고 사항

- LLM 호출은 네트워크 지연과 API 응답 시간에 의존적
- OpenAI API의 rate limit 확인 필요 (일반적으로 분당 60-5000 요청)
- 병렬 처리 시 동시 요청 수 제한 고려 (예: 최대 3-5개)
- 캐싱은 메모리 사용량 증가 가능성 있음
