# core_pipeline/reasoning_engine.py
# -*- coding: utf-8 -*-
"""
Reasoning Engine
ê·œì¹™ ê¸°ë°˜ ì¶”ë¡  ì—”ì§„ ëª¨ë“ˆ
íŒ”ë€í‹°ì–´ ë°©ì‹: ë‹¤ì¤‘ ìš”ì†Œ ê¸°ë°˜ ì¶”ë¡  ì§€ì›
"""
from typing import Dict, List, Optional
import pandas as pd
import os
import sys

# ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, BASE_DIR)

try:
    from agents.defense_coa_agent.rule_engine import RuleEngine
    RULE_ENGINE_AVAILABLE = True
except ImportError:
    RULE_ENGINE_AVAILABLE = False
    print("[WARN] RuleEngineì„ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·œì¹™ ì—”ì§„ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")


class ReasoningEngine:
    """ì¶”ë¡  ì—”ì§„ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Optional[Dict] = None,
                 relevance_mapper=None,  # [NEW] ì£¼ì…
                 resource_parser=None):  # [NEW] ì£¼ì…
        """
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ì„ íƒì )
            relevance_mapper: RelevanceMapper ì¸ìŠ¤í„´ìŠ¤ (ì£¼ì…ìš©)
            resource_parser: ResourcePriorityParser ì¸ìŠ¤í„´ìŠ¤ (ì£¼ì…ìš©)
        """
        self.config = config or {}
        self.use_palantir_mode = self.config.get("use_palantir_mode", False)
        
        # [FIXED] ì£¼ì…ëœ ë§¤í¼ ì €ì¥
        self.relevance_mapper = relevance_mapper
        self.resource_parser = resource_parser
        
        # ê·œì¹™ ì—”ì§„ ì´ˆê¸°í™” (ê°€ëŠ¥í•œ ê²½ìš°)
        self.rule_engine = None
        if RULE_ENGINE_AVAILABLE:
            try:
                self.rule_engine = RuleEngine()
            except Exception as e:
                print(f"[WARN] ê·œì¹™ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.rule_engine = None
    
    # ë™ì  ì¶”ë¡ ì„ ìœ„í•œ ê·œì¹™ ì •ì˜
    DYNAMIC_RULES = {
        'terrain': {
            'Mountains': {'Mechanized': -0.3, 'Armor': -0.4, 'Infantry': 0.1, 'Air': -0.1},
            'Urban': {'Mechanized': -0.2, 'Armor': -0.3, 'Infantry': 0.2},
            'Plains': {'Mechanized': 0.1, 'Armor': 0.2, 'Infantry': -0.1},
            'River': {'Mechanized': -0.5, 'Armor': -0.5, 'Engineer': 0.3}
        },
        'weather': {
            'Rain': {'Air': -0.4, 'Mechanized': -0.1},
            'Fog': {'Air': -0.6, 'Recon': -0.5},
            'Snow': {'Mechanized': -0.2, 'Infantry': -0.2}
        }
    }

    def evaluate_scores(self, features: Dict[str, float], weights: Optional[Dict[str, float]] = None) -> float:
        """
        íŠ¹ì§•ê°’ê³¼ ê°€ì¤‘ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
        
        Args:
            features: {íŠ¹ì§•ëª…: ê°’} ë”•ì…”ë„ˆë¦¬
            weights: {íŠ¹ì§•ëª…: ê°€ì¤‘ì¹˜} ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ëª¨ë‘ 1.0)
            
        Returns:
            ê³„ì‚°ëœ ì ìˆ˜
        """
        if weights is None:
            weights = {k: 1.0 for k in features}
        
        score = sum(features.get(k, 0) * weights.get(k, 1.0) for k in features)
        return score

    def calculate_dynamic_score(self, coa, context: Dict) -> float:
        """
        [NEW] ë™ì  ì¶”ë¡  ì ìˆ˜ ê³„ì‚°
        ì§€í˜•, ê¸°ìƒ ë“± ìƒí™© ë³€ìˆ˜ì— ë”°ë¼ ê¸°ë³¸ ì ìˆ˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
        
        Args:
            coa: COA ê°ì²´ (coa_id, coa_name, description ë“± ì†ì„± í•„ìš”)
            context: ìƒí™© ì»¨í…ìŠ¤íŠ¸ (terrain, weather í‚¤ í¬í•¨)
            
        Returns:
            ì¡°ì •ëœ ì ìˆ˜ (0.0 ~ 1.0)
        """
        # 1. ê¸°ë³¸ ì ìˆ˜ ì„¤ì • (ì…ë ¥ê°’ì´ ì—†ìœ¼ë©´ 0.5)
        base_score = context.get('base_score', 0.5)
        current_score = base_score
        
        # 2. COA íƒ€ì… ì¶”ë¡  (ì´ë¦„/ID ê¸°ë°˜ ë‹¨ìˆœ ì¶”ë¡ )
        coa_name = str(getattr(coa, 'coa_name', '') or getattr(coa, 'coa_id', '')).lower()
        coa_desc = str(getattr(coa, 'description', '')).lower()
        full_text = f"{coa_name} {coa_desc}"
        
        # ë¶€ëŒ€/ì‘ì „ ìœ í˜• ì‹ë³„
        unit_types = []
        if any(x in full_text for x in ['ê¸°ê³„í™”', 'mechanized', 'tank', 'ì „ì°¨']):
            unit_types.append('Mechanized')
            unit_types.append('Armor')
        if any(x in full_text for x in ['ë³´ë³‘', 'infantry', 'íŠ¹ìˆ˜ì „', 'special forces']):
            unit_types.append('Infantry')
        if any(x in full_text for x in ['í•­ê³µ', 'air', 'í—¬ê¸°', 'helicopter']):
            unit_types.append('Air')
        if any(x in full_text for x in ['ê³µë³‘', 'engineer']):
            unit_types.append('Engineer')
        if any(x in full_text for x in ['ì •ì°°', 'recon']):
            unit_types.append('Recon')
            
        # 3. ì§€í˜•(Terrain) íš¨ê³¼ ì ìš©
        terrain = context.get('terrain', 'Plains') # ê¸°ë³¸ê°’: í‰ì§€
        terrain_rules = self.DYNAMIC_RULES['terrain'].get(terrain, {})
        
        for u_type in unit_types:
            if u_type in terrain_rules:
                adjustment = terrain_rules[u_type]
                current_score += adjustment
                # print(f"[DEBUG] ì§€í˜• íš¨ê³¼({terrain}): {u_type} -> {adjustment:+.1f}")

        # 4. ê¸°ìƒ(Weather) íš¨ê³¼ ì ìš©
        weather = context.get('weather', 'Clear') # ê¸°ë³¸ê°’: ë§‘ìŒ
        weather_rules = self.DYNAMIC_RULES['weather'].get(weather, {})
        
        for u_type in unit_types:
            if u_type in weather_rules:
                adjustment = weather_rules[u_type]
                current_score += adjustment
                # print(f"[DEBUG] ê¸°ìƒ íš¨ê³¼({weather}): {u_type} -> {adjustment:+.1f}")
                
        # 5. ì ìˆ˜ ë²”ìœ„ ì œí•œ (0.0 ~ 1.0)
        return min(1.0, max(0.0, current_score))
    
    def run_defense_rules(self, context: Dict) -> Dict:
        """
        ë°©ì–´ ê·œì¹™ ì‹¤í–‰
        
        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬ (graph, data ë“± í¬í•¨ ê°€ëŠ¥)
            
        Returns:
            ë°©ì–´ COA ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # íŒ”ë€í‹°ì–´ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        if self.use_palantir_mode or context.get("use_palantir_mode", False):
            return self._run_defense_rules_palantir(context)
        else:
            return self._run_defense_rules_basic(context)

    def run_offensive_rules(self, context: Dict) -> Dict:
        """ê³µê²© ê·œì¹™ ì‹¤í–‰"""
        if self.use_palantir_mode or context.get("use_palantir_mode", False):
            return self._run_offensive_rules_palantir(context)
        else:
            return self._run_offensive_rules_basic(context)

    def run_counter_attack_rules(self, context: Dict) -> Dict:
        """ë°˜ê²© ê·œì¹™ ì‹¤í–‰"""
        if self.use_palantir_mode or context.get("use_palantir_mode", False):
            return self._run_counter_attack_rules_palantir(context)
        else:
            return self._run_counter_attack_rules_basic(context)

    def run_preemptive_rules(self, context: Dict) -> Dict:
        """ì„ ì œ ê³µê²© ê·œì¹™ ì‹¤í–‰"""
        if self.use_palantir_mode or context.get("use_palantir_mode", False):
            return self._run_preemptive_rules_palantir(context)
        else:
            return self._run_preemptive_rules_basic(context)

    def run_deterrence_rules(self, context: Dict) -> Dict:
        """ì–µì œ ê·œì¹™ ì‹¤í–‰"""
        if self.use_palantir_mode or context.get("use_palantir_mode", False):
            return self._run_deterrence_rules_palantir(context)
        else:
            return self._run_deterrence_rules_basic(context)

    def run_maneuver_rules(self, context: Dict) -> Dict:
        """ê¸°ë™ ê·œì¹™ ì‹¤í–‰"""
        if self.use_palantir_mode or context.get("use_palantir_mode", False):
            return self._run_maneuver_rules_palantir(context)
        else:
            return self._run_maneuver_rules_basic(context)

    def run_information_ops_rules(self, context: Dict) -> Dict:
        """ì •ë³´ ì‘ì „ ê·œì¹™ ì‹¤í–‰"""
        if self.use_palantir_mode or context.get("use_palantir_mode", False):
            return self._run_information_ops_rules_palantir(context)
        else:
            return self._run_information_ops_rules_basic(context)

    def run_coa_rules(self, context: Dict, coa_type: str = "defense") -> Dict:
        """
        ë²”ìš© COA ê·œì¹™ ì‹¤í–‰ (íƒ€ì…ë³„ ë¶„ê¸°)
        
        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
            coa_type: ë°©ì±… íƒ€ì… ("defense", "offensive", "counter_attack", ë“±)
            
        Returns:
            COA ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        type_map = {
            "defense": self.run_defense_rules,
            "offensive": self.run_offensive_rules,
            "counter_attack": self.run_counter_attack_rules,
            "preemptive": self.run_preemptive_rules,
            "deterrence": self.run_deterrence_rules,
            "maneuver": self.run_maneuver_rules,
            "information_ops": self.run_information_ops_rules
        }
        
        rule_func = type_map.get(coa_type.lower(), self.run_defense_rules)
        return rule_func(context)
    
    def _run_defense_rules_basic(self, context: Dict) -> Dict:
        """ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ì¶”ë¡  (YAML ê·œì¹™ íŒŒì¼ ìš°ì„  ì‚¬ìš©)"""
        threat_level = context.get("threat_level", 0.5)
        defense_assets = context.get("defense_assets", [])
        
        # ê·¸ë˜í”„ì—ì„œ ìœ„í˜‘ ì •ë³´ ì¶”ì¶œ ì‹œë„
        graph = context.get("graph")
        if graph is not None:
            try:
                from rdflib import URIRef, Literal
                ns = context.get("namespace")
                if ns:
                    # [REFACTORED] SPARQL ì¿¼ë¦¬ ëŒ€ì‹  graph.triples() ì‚¬ìš©
                    max_threat = 0.0
                    threat_level_prop = ns.ThreatLevel
                    for s, p, o in graph.triples((None, threat_level_prop, None)):
                        try:
                            val = float(str(o))
                            if val > 80 and val > max_threat:
                                max_threat = val
                        except (ValueError, TypeError):
                            continue
                    
                    if max_threat > 0:
                        threat_level = max_threat / 100.0
            except Exception:
                pass
        
        # ê·œì¹™ ì—”ì§„ ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.rule_engine is not None:
            try:
                rule_context = {
                    "threat_level": threat_level
                }
                recommended_coa = self.rule_engine.get_recommended_coa(rule_context)
                
                if recommended_coa:
                    return {
                        "COA": recommended_coa.get("coa", "Unknown"),
                        "Reason": f"Rule: {recommended_coa.get('rule_name', 'Unknown')}",
                        "ThreatLevel": threat_level,
                        "DefenseAssets": len(defense_assets),
                        "RuleApplied": True,
                        "RuleName": recommended_coa.get("rule_name")
                    }
            except Exception as e:
                print(f"[WARN] ê·œì¹™ ì—”ì§„ ì‹¤í–‰ ì‹¤íŒ¨, ê¸°ë³¸ ë¡œì§ ì‚¬ìš©: {e}")
        
        # í´ë°±: ê¸°ë³¸ ê·œì¹™ (YAML ê·œì¹™ íŒŒì¼ì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°)
        if threat_level > 0.7:
            coa = "Main_Defense"
            reason = "High Threat Level"
        elif threat_level > 0.4:
            coa = "Moderate_Defense"
            reason = "Moderate Threat Level"
        else:
            coa = "Minimal_Defense"
            reason = "Low Threat Level"
        
        return {
            "COA": coa,
            "Reason": reason,
            "ThreatLevel": threat_level,
            "DefenseAssets": len(defense_assets),
            "RuleApplied": False
        }
    
    def _run_defense_rules_palantir(self, context: Dict) -> Dict:
        """íŒ”ë€í‹°ì–´ ë°©ì‹: ë‹¤ì¤‘ ìš”ì†Œ ê¸°ë°˜ ì¶”ë¡  + ì²´ì¸ íƒìƒ‰"""
        from core_pipeline.coa_scorer import COAScorer
        
        # [FIXED] ì£¼ì…ëœ ë§¤í¼ ì „ë‹¬ (ì„±ëŠ¥ ìµœì í™”)
        scorer = COAScorer(
            data_manager=data_manager, 
            config=config,
            relevance_mapper=self.relevance_mapper,
            resource_parser=self.resource_parser
        )
        
        # 1. ìœ„í˜‘ ì ìˆ˜ ê³„ì‚°
        threat_score = self._extract_threat_score(context)
        
        # 2. ìì› ê°€ìš©ì„± ê³„ì‚°
        resource_availability = self._extract_resource_availability(context)
        
        # 3. ë°©ì–´ ìì‚° ëŠ¥ë ¥ ê³„ì‚°
        asset_capability = self._extract_asset_capability(context)
        
        # 4. í™˜ê²½ ì í•©ì„± ê³„ì‚°
        environment_fit = self._extract_environment_fit(context)
        
        # 5. ê³¼ê±° ì„±ê³µë¥  ê³„ì‚° (RAG ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°)
        historical_success = self._extract_historical_success(context)
        
        # 6. ì²´ì¸ ê¸°ë°˜ COA ì ìˆ˜ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        chain_score = self._extract_chain_score(context)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ì»¨í…ìŠ¤íŠ¸ì— ëª¨ë“  ì •ë³´ í¬í•¨)
        score_context = {
            'threat_score': threat_score,
            'resource_availability': resource_availability,
            'asset_capability': asset_capability,
            'environment_fit': environment_fit,
            'historical_success': historical_success,
            'chain_score': chain_score,  # ì²´ì¸ ì ìˆ˜ ì¶”ê°€
            # ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì €ì™€ ê·¸ë˜í”„ ì „ë‹¬ (ì¶”ê°€ ì ìˆ˜ ê³„ì‚°ì— í•„ìš”)
            'ontology_manager': context.get('ontology_manager'),
            'graph': context.get('graph'),
            'coa_uri': context.get('coa_uri'),
            'situation_id': context.get('situation_id')
        }
        score_result = scorer.calculate_score(score_context)
        
        # ì²´ì¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        chain_info = context.get("chain_info", {})
        
        # ì ìˆ˜ì— ë”°ë¥¸ COA ê²°ì •
        total_score = score_result['total']
        if total_score > 0.7:
            coa = "Main_Defense"
            reason = f"High Comprehensive Score ({total_score:.2f})"
        elif total_score > 0.4:
            coa = "Moderate_Defense"
            reason = f"Moderate Comprehensive Score ({total_score:.2f})"
        else:
            coa = "Minimal_Defense"
            reason = f"Low Comprehensive Score ({total_score:.2f})"
        
        result = {
            "COA": coa,
            "Reason": reason,
            "ThreatLevel": threat_score,
            "DefenseAssets": len(context.get("defense_assets", [])),
            "TotalScore": total_score,
            "ScoreBreakdown": score_result['breakdown'],
            "PalantirMode": True
        }
        
        # ì²´ì¸ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if chain_info:
            result["ChainInfo"] = chain_info
        
        return result

    def _run_offensive_rules_basic(self, context: Dict) -> Dict:
        """ê³µê²© ê¸°ë³¸ ê·œì¹™"""
        threat_level = context.get("threat_level", 0.5)
        # ê°„ë‹¨í•œ ë¡œì§ ì˜ˆì‹œ
        if threat_level > 0.6:
            coa = "Main_Offensive"
            reason = "High Opportunity for Attack"
        else:
            coa = "Limited_Offensive"
            reason = "Limited Opportunity"
            
        return {
            "COA": coa,
            "Reason": reason,
            "ThreatLevel": threat_level,
            "RuleApplied": False
        }

    def _run_offensive_rules_palantir(self, context: Dict) -> Dict:
        """ê³µê²© íŒ”ë€í‹°ì–´ ê·œì¹™"""
        # Defenseì™€ ìœ ì‚¬í•˜ê²Œ êµ¬í˜„í•˜ë˜ ê°€ì¤‘ì¹˜ë§Œ ë‹¤ë¥´ê²Œ ì ìš©ë  ì˜ˆì •
        # ì—¬ê¸°ì„œëŠ” ì¬ì‚¬ìš©ì„±ì„ ìœ„í•´ _run_generic_palantir í˜¸ì¶œ ê¶Œì¥í•˜ì§€ë§Œ,
        # ì¼ë‹¨ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„í•˜ê±°ë‚˜ ê¸°ì¡´ ë¡œì§ í™œìš©
        return self._run_generic_palantir(context, "offensive")

    def _run_counter_attack_rules_basic(self, context: Dict) -> Dict:
        """ë°˜ê²© ê¸°ë³¸ ê·œì¹™"""
        return {"COA": "Counter_Attack_Alpha", "Reason": "Basic Rule", "RuleApplied": False}

    def _run_counter_attack_rules_palantir(self, context: Dict) -> Dict:
        return self._run_generic_palantir(context, "counter_attack")

    def _run_preemptive_rules_basic(self, context: Dict) -> Dict:
        return {"COA": "Preemptive_Strike", "Reason": "Basic Rule", "RuleApplied": False}

    def _run_preemptive_rules_palantir(self, context: Dict) -> Dict:
        return self._run_generic_palantir(context, "preemptive")

    def _run_deterrence_rules_basic(self, context: Dict) -> Dict:
        return {"COA": "Show_Of_Force", "Reason": "Basic Rule", "RuleApplied": False}

    def _run_deterrence_rules_palantir(self, context: Dict) -> Dict:
        return self._run_generic_palantir(context, "deterrence")

    def _run_maneuver_rules_basic(self, context: Dict) -> Dict:
        return {"COA": "Flanking_Maneuver", "Reason": "Basic Rule", "RuleApplied": False}

    def _run_maneuver_rules_palantir(self, context: Dict) -> Dict:
        return self._run_generic_palantir(context, "maneuver")

    def _run_information_ops_rules_basic(self, context: Dict) -> Dict:
        return {"COA": "Cyber_Disruption", "Reason": "Basic Rule", "RuleApplied": False}

    def _run_information_ops_rules_palantir(self, context: Dict) -> Dict:
        return self._run_generic_palantir(context, "information_ops")

    def _run_generic_palantir(self, context: Dict, coa_type: str) -> Dict:
        """ë²”ìš© íŒ”ë€í‹°ì–´ ëª¨ë“œ ì‹¤í–‰"""
        from core_pipeline.coa_scorer import COAScorer
        
        # [FIXED] ì£¼ì…ëœ ë§¤í¼ ì „ë‹¬ (ì„±ëŠ¥ ìµœì í™”)
        scorer = COAScorer(
            data_manager=data_manager, 
            config=config, 
            coa_type=coa_type,
            relevance_mapper=self.relevance_mapper,
            resource_parser=self.resource_parser
        )
        
        # ì ìˆ˜ ìš”ì†Œ ì¶”ì¶œ (ê¸°ì¡´ ë©”ì„œë“œ ì¬ì‚¬ìš©)
        threat_score = self._extract_threat_score(context)
        resource_availability = self._extract_resource_availability(context)
        asset_capability = self._extract_asset_capability(context)
        environment_fit = self._extract_environment_fit(context)
        historical_success = self._extract_historical_success(context)
        chain_score = self._extract_chain_score(context)
        
        score_context = {
            'threat_score': threat_score,
            'resource_availability': resource_availability,
            'asset_capability': asset_capability,
            'environment_fit': environment_fit,
            'historical_success': historical_success,
            'chain_score': chain_score,
            'ontology_manager': context.get('ontology_manager'),
            'graph': context.get('graph'),
            'coa_uri': context.get('coa_uri'),
            'situation_id': context.get('situation_id')
        }
        
        score_result = scorer.calculate_score(score_context)
        total_score = score_result['total']
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            "COA": f"Best_{coa_type.capitalize()}", # ì„ì‹œ ëª…ì¹­
            "Reason": f"High Score ({total_score:.2f})",
            "ThreatLevel": threat_score,
            "TotalScore": total_score,
            "ScoreBreakdown": score_result['breakdown'],
            "PalantirMode": True,
            "COAType": coa_type
        }
        
        if context.get("chain_info"):
            result["ChainInfo"] = context.get("chain_info")
            
        return result
    
    def _extract_threat_score(self, context: Dict) -> float:
        """ìœ„í˜‘ ì ìˆ˜ ì¶”ì¶œ"""
        # contextì—ì„œ ì§ì ‘ threat_level ê°€ì ¸ì˜¤ê¸° (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        threat_level = context.get("threat_level")
        
        # threat_levelì´ ì´ë¯¸ ì œê³µë˜ì—ˆìœ¼ë©´ ì •ê·œí™” í›„ ë°˜í™˜
        if threat_level is not None and isinstance(threat_level, (int, float)):
            if threat_level > 1.0:
                threat_level = threat_level / 100.0
            return min(1.0, max(0.0, threat_level))
        
        # threat_levelì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        threat_level = 0.5
        
        # ê·¸ë˜í”„ì—ì„œ ìœ„í˜‘ ì •ë³´ ì¶”ì¶œ ì‹œë„ (ë³´ì¡°ì , contextì˜ ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        graph = context.get("graph")
        if graph is not None:
            try:
                ns = context.get("namespace")
                if ns:
                    # [REFACTORED] SPARQL ëŒ€ì‹  graph.triples() ì‚¬ìš©
                    max_val = 0.0
                    threat_level_prop = URIRef("http://coa-agent-platform.org/ontology#ThreatLevel")
                    for s, p, o in graph.triples((None, threat_level_prop, None)):
                        try:
                            val = float(str(o))
                            if val > max_val:
                                max_val = val
                        except (ValueError, TypeError):
                            continue
                    
                    if max_val > 0:
                        graph_threat = max_val / 100.0 if max_val > 1.0 else max_val
                        if graph_threat > threat_level:
                            threat_level = graph_threat
            except Exception:
                pass
        
        return min(1.0, max(0.0, threat_level))
    
    def _extract_resource_availability(self, context: Dict) -> float:
        """ìì› ê°€ìš©ì„± ì¶”ì¶œ (ë¡œê¹… ë° ê²€ì¦ ê°•í™”)"""
        ontology_manager = context.get("ontology_manager")
        situation_id = context.get("situation_id")
        coa_uri = context.get("coa_uri")  # ì‹¤ì œ COA URI ì‚¬ìš©
        
        # ì§ì ‘ ì œê³µëœ ìì› ê°€ìš©ì„± ì‚¬ìš©
        if "resource_availability" in context:
            return float(context["resource_availability"])
        
        if not ontology_manager or not hasattr(ontology_manager, 'execute_template_query'):
            from common.utils import safe_print
            safe_print("[WARN] OntologyManager ë˜ëŠ” execute_template_query ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’(0.5) ì‚¬ìš©", logger_name="ReasoningEngine")
            return 0.5
        
        if not situation_id:
            situation_id = "THREAT001"  # ê¸°ë³¸ê°’ (ìœ„í˜‘ìƒí™© ID í˜•ì‹)
            from common.utils import safe_print
            safe_print(f"[INFO] situation_idê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {situation_id}", logger_name="ReasoningEngine")
        
        try:
            from common.utils import safe_print
            required_resources = []
            available_resources = []
            
            # COAë³„ í•„ìš”í•œ ìì› ì¡°íšŒ (coa_uriê°€ ìˆëŠ” ê²½ìš°)
            if coa_uri:
                safe_print(f"[INFO] ìì› ê°€ìš©ì„± ì¡°íšŒ: COA={coa_uri}, Situation={situation_id}", logger_name="ReasoningEngine")
                from rdflib import URIRef
                coa_node = URIRef(coa_uri)
                ns = ontology_manager.ns
                
                required_resources_nodes = []
                # ns:requiresResource OR ns:í•„ìš”ìì›
                for o in ontology_manager.graph.objects(coa_node, ns.requiresResource):
                    required_resources_nodes.append(o)
                for o in ontology_manager.graph.objects(coa_node, ns.í•„ìš”ìì›):
                    required_resources_nodes.append(o)
                
                if required_resources_nodes:
                    required_resources = [str(r) for r in required_resources_nodes]
                    safe_print(f"[INFO] í•„ìš”í•œ ìì›: {len(required_resources)}ê°œ - {required_resources[:3]}", logger_name="ReasoningEngine")
                else:
                    # ğŸ”¥ ë¡œê·¸ ìµœì í™”: ì²« ë²ˆì§¸ COAì—ì„œë§Œ ê²½ê³  ì¶œë ¥ (ë°˜ë³µ ë°©ì§€)
                    if not hasattr(self, '_resource_warning_logged'):
                        safe_print(f"[WARN] COA {coa_uri}ì— ëŒ€í•œ í•„ìš”í•œ ìì›ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ ê²½ê³ ëŠ” ì²« ë²ˆì§¸ COAì—ì„œë§Œ í‘œì‹œë©ë‹ˆë‹¤)", logger_name="ReasoningEngine")
                        self._resource_warning_logged = True
            else:
                safe_print(f"[WARN] coa_uriê°€ ì—†ì–´ í•„ìš”í•œ ìì› ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.", logger_name="ReasoningEngine")
            
            # ìƒí™©ë³„ ê°€ìš© ìì› ì¡°íšŒ
            from rdflib import URIRef, RDF
            ns = ontology_manager.ns
            
            # [IMPROVED] Situation ID(ìœ„í˜‘ID)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì„ë¬´(Mission) ì‹ë³„
            # THREAT001 -> ì‹œë‚˜ë¦¬ì˜¤ -> ì„ë¬´ -> ê°€ìš©ìì› ì—°ê²° ê³ ë¦¬ ì¶”ì 
            target_mission_nodes = []
            
            # 1. ì…ë ¥ IDë¡œ ì§ì ‘ Mission/Scenario ë…¸ë“œ ì°¾ê¸° ì‹œë„
            if "MSN" in situation_id:
                # Mission IDì¸ ê²½ìš°
                target_mission_nodes.append(URIRef(ns[f"ì„ë¬´ì •ë³´_{situation_id}"]))
            elif "THR" in situation_id or "THREAT" in situation_id:
                # Threat IDì¸ ê²½ìš° -> ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ Mission ì°¾ê¸°
                # ID ì •ê·œí™”: THREAT001 -> THR001 (ë°ì´í„° ì •í•©ì„± ì´ìŠˆ ëŒ€ì‘)
                normalized_id = situation_id.replace("THREAT", "THR")
                threat_uri_candidates = [
                    URIRef(ns[f"ìœ„í˜‘ìƒí™©_{situation_id}"]), 
                    URIRef(ns[f"ìœ„í˜‘ìƒí™©_{normalized_id}"])
                ]
                
                for threat_node in threat_uri_candidates:
                    # ?scenario ns:hasìœ„í˜‘ìƒí™© ?threat_node
                    for scenario in ontology_manager.graph.subjects(ns.hasìœ„í˜‘ìƒí™©, threat_node):
                        # ?scenario ns:hasì„ë¬´ì •ë³´ ?mission
                        for mission in ontology_manager.graph.objects(scenario, ns.hasì„ë¬´ì •ë³´):
                            target_mission_nodes.append(mission)
            
            if not target_mission_nodes:
                # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ situation_idë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ í´ë°±
                 target_mission_nodes.append(URIRef(situation_id if situation_id.startswith('http') else f"http://coa-agent-platform.org/ontology#{situation_id}"))
                 # ê¸°ë³¸ Mission ID(MSN001) ì¶”ê°€ ì‹œë„ (ë°ì´í„° ëˆ„ë½ ëŒ€ë¹„)
                 target_mission_nodes.append(URIRef(ns["ì„ë¬´ì •ë³´_MSN001"]))

            # [IMPROVED] ëª¨ë“  ê´€ë ¨ ë…¸ë“œ(Mission + Threat)ì—ì„œ ìì› ìˆ˜ì§‘
            search_nodes = list(target_mission_nodes)
            if "THR" in situation_id or "THREAT" in situation_id:
                # ìœ„í˜‘ ìƒí™© ë…¸ë“œë„ ê²€ìƒ‰ ëŒ€ìƒì— í¬í•¨ (hasResourceSnapshotì´ ìœ„í˜‘ ìƒí™©ì— ì—°ê²°ë  ìˆ˜ ìˆìŒ)
                normalized_id = situation_id.replace("THREAT", "THR")
                search_nodes.append(URIRef(ns[f"ìœ„í˜‘ìƒí™©_{situation_id}"]))
                if normalized_id != situation_id:
                    search_nodes.append(URIRef(ns[f"ìœ„í˜‘ìƒí™©_{normalized_id}"]))

            available_nodes = set()
            for node_to_check in search_nodes:
                # 1. ì—°ê²°ëœ ê°€ìš© ìì› (ns:AvailableResource ns:forScenario ?node)
                for res in ontology_manager.graph.subjects(ns.forScenario, node_to_check):
                    available_nodes.add(res)
                
                # 2. ì§ì ‘ ì—°ê²°ëœ ìì› 
                for o in ontology_manager.graph.objects(node_to_check, ns.hasAvailableResource):
                    available_nodes.add(o)
                for o in ontology_manager.graph.objects(node_to_check, ns.hasê°€ìš©ìì›):
                    available_nodes.add(o)
                # [NEW] ê°€ìš©ìì› ìŠ¤ëƒ…ìƒ· í†µí•© (OntologyManagerEnhancedì—ì„œ ìƒì„±í•œ ê´€ê³„)
                for o in ontology_manager.graph.objects(node_to_check, ns.hasResourceSnapshot):
                    available_nodes.add(o)

                # 3. ì§€í˜•ì…€ ê¸°ë°˜ (Legacy)
                for loc in ontology_manager.graph.objects(node_to_check, ns.hasì§€í˜•ì…€):

                     for res, p, o in ontology_manager.graph.triples((None, ns.hasì§€í˜•ì…€, loc)):
                        available_nodes.add(res)
            
            if available_nodes:
                available_resources = [str(a) for a in available_nodes]
                # ìì‚°/ë¶€ëŒ€ ì¹´ìš´íŠ¸
                asset_count = sum(1 for a in available_nodes if (a, RDF.type, ns.ì•„êµ°ê°€ìš©ìì‚°) in ontology_manager.graph)
                unit_count = sum(1 for a in available_nodes if (a, RDF.type, ns.ì•„êµ°ë¶€ëŒ€í˜„í™©) in ontology_manager.graph)
                res_count = sum(1 for a in available_nodes if (a, RDF.type, ns.AvailableResource) in ontology_manager.graph)
                legacy_count = sum(1 for a in available_nodes if (a, RDF.type, ns.ê°€ìš©ìì›) in ontology_manager.graph)
                
                if context.get('is_first_coa', False):
                    safe_print(f"[INFO] ê°€ìš© ìì›: {len(available_nodes)}ê°œ (ì¼ë°˜: {res_count}, ìì‚°: {asset_count}, ë¶€ëŒ€: {unit_count}, ë ˆê±°ì‹œ: {legacy_count})", logger_name="ReasoningEngine")

            else:
                # ğŸ”¥ ë¡œê·¸ ìµœì í™”: ì²« ë²ˆì§¸ COAì—ì„œë§Œ ê²½ê³  ì¶œë ¥ (ë°˜ë³µ ë°©ì§€)
                if not hasattr(self, '_available_resource_warning_logged'):
                    safe_print(f"[WARN] ìƒí™© {situation_id} (Mission Candidates: {target_mission_nodes})ì— ëŒ€í•œ ê°€ìš© ìì›ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ ê²½ê³ ëŠ” ì²« ë²ˆì§¸ COAì—ì„œë§Œ í‘œì‹œë©ë‹ˆë‹¤)", logger_name="ReasoningEngine")
                    self._available_resource_warning_logged = True
            
            # ìì› ë§¤ì¹­ë¥  ê³„ì‚° (íŒ”ë€í‹°ì–´ ë°©ì‹: ë‹¤ì¸µ ë§¤ì¹­ + í’ˆì§ˆ ë°˜ì˜)
            if required_resources and available_resources:
                # 1. ì§ì ‘ URI ë§¤ì¹­ ì‹œë„
                matched = set(required_resources) & set(available_resources)
                
                # 2. ê°œë…ì  ìì›ê³¼ ë¶€ëŒ€ ì¸ìŠ¤í„´ìŠ¤ ë§¤ì¹­ (ì§ì ‘ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
                if len(matched) == 0:
                    matched_count = 0.0
                    for req_resource_uri in required_resources:
                        # ê°œë…ì  ìì› ì¶”ì¶œ (URIì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„)
                        required_concept = req_resource_uri.split('#')[-1] if '#' in req_resource_uri else req_resource_uri
                        required_concept_lower = required_concept.lower()
                        
                        # ê° ê°€ìš© ë¶€ëŒ€ì™€ ë§¤ì¹­ ì‹œë„ (íŒ”ë€í‹°ì–´ ë°©ì‹: ì‹ ë¢°ë„ ì ìˆ˜ í™œìš©)
                        best_match_score = 0.0
                        best_match_unit = None
                        debug_mode = context.get('is_first_coa', False)
                        for avail_unit_uri in available_resources:
                            is_match, confidence = self._match_resource_concept_to_unit_enhanced(
                                required_concept_lower, 
                                avail_unit_uri, 
                                ontology_manager,
                                debug=debug_mode
                            )
                            if is_match:
                                if confidence > best_match_score:
                                    best_match_score = confidence
                                    best_match_unit = avail_unit_uri
                                if context.get('is_first_coa', False):
                                    safe_print(f"[INFO] ìì› ë§¤ì¹­ ì„±ê³µ: '{required_concept}' <-> '{avail_unit_uri}' (ì‹ ë¢°ë„: {confidence:.2f})", logger_name="ReasoningEngine")
                        
                        # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ (ì²« ë²ˆì§¸ COAì—ì„œë§Œ)
                        # ğŸ”¥ ìµœì í™”: ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ ì œê±° (ìš”ì•½ ë¡œê·¸ë¡œ ëŒ€ì²´)
                        # if best_match_score == 0.0 and context.get('is_first_coa', False):
                        #     # ë¶€ëŒ€ ì†ì„± ì¡°íšŒ ê²°ê³¼ í™•ì¸
                        #     if available_resources:
                        #         sample_unit = available_resources[0]
                        #         unit_props = self._get_unit_properties(sample_unit, ontology_manager)
                        #         safe_print(f"[DEBUG] ë§¤ì¹­ ì‹¤íŒ¨ ë¶„ì„: required='{required_concept}', sample_unit='{sample_unit}', unit_props={unit_props}", logger_name="ReasoningEngine")
                        
                        # ëŒ€ì²´ ìì› í™•ì¸ (NEW: íŒ”ë€í‹°ì–´ ë°©ì‹)
                        if best_match_score < 0.5:
                            alternatives = self._find_alternative_resources(req_resource_uri, context)
                            for alt_resource in alternatives:
                                is_match, confidence = self._match_resource_concept_to_unit_enhanced(
                                    required_concept_lower,
                                    alt_resource,
                                    ontology_manager,
                                    debug=debug_mode
                                )
                                if is_match:
                                    if confidence * 0.8 > best_match_score:
                                        best_match_score = confidence * 0.8  # ëŒ€ì²´ ìì›ì€ 80% ê°€ì¤‘ì¹˜
                                        best_match_unit = alt_resource
                                    if context.get('is_first_coa', False):
                                        safe_print(f"[INFO] ëŒ€ì²´ ìì› ë§¤ì¹­: '{required_concept}' <-> '{alt_resource}' (ì‹ ë¢°ë„: {confidence * 0.8:.2f})", logger_name="ReasoningEngine")
                        
                        # ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ëˆ„ì  (ë¶€ë¶„ ë§¤ì¹­ë„ ë°˜ì˜)
                        matched_count += best_match_score
                    
                    # ë§¤ì¹­ë¥  = ëˆ„ì  ì‹ ë¢°ë„ ì ìˆ˜ / í•„ìš”í•œ ìì› ìˆ˜
                    match_ratio = matched_count / len(required_resources) if len(required_resources) > 0 else 0.0
                    
                    # ìì› í’ˆì§ˆ ë°˜ì˜ (íŒ”ë€í‹°ì–´ ë°©ì‹)
                    quality_score = self._calculate_resource_quality(available_resources, ontology_manager)
                    match_ratio = match_ratio * quality_score  # ë§¤ì¹­ë¥  * í’ˆì§ˆ
                    
                    if context.get('is_first_coa', False):
                        safe_print(f"[INFO] ìì› ë§¤ì¹­ë¥ : {matched_count:.2f}/{len(required_resources)} = {match_ratio:.2f} (í’ˆì§ˆ ë°˜ì˜: {quality_score:.2f})", logger_name="ReasoningEngine")
                else:
                    # ì§ì ‘ URI ë§¤ì¹­ ì„±ê³µ
                    match_ratio = len(matched) / len(required_resources) if len(required_resources) > 0 else 0.0
                    # ì§ì ‘ ë§¤ì¹­ëœ ê²½ìš°ì—ë„ í’ˆì§ˆ ë°˜ì˜
                    quality_score = self._calculate_resource_quality(available_resources, ontology_manager)
                    match_ratio = match_ratio * quality_score
                    if context.get('is_first_coa', False):
                        safe_print(f"[INFO] ìì› ë§¤ì¹­ë¥ : {len(matched)}/{len(required_resources)} = {match_ratio:.2f} (í’ˆì§ˆ ë°˜ì˜: {quality_score:.2f})", logger_name="ReasoningEngine")
                
                return match_ratio
            elif not required_resources and available_resources:
                # í•„ìš”í•œ ìì› ì •ë³´ê°€ ì—†ìœ¼ë©´ ê°€ìš© ìì›ì´ ìˆìœ¼ë©´ ë†’ì€ ì ìˆ˜
                safe_print("[INFO] í•„ìš”í•œ ìì› ì •ë³´ ì—†ìŒ. ê°€ìš© ìì› ì¡´ì¬ë¡œ ì¸í•´ ë†’ì€ ì ìˆ˜(0.8) ì‚¬ìš©", logger_name="ReasoningEngine")
                return 0.8
            elif required_resources and not available_resources:
                # í•„ìš”í•œ ìì›ì´ ìˆì§€ë§Œ ê°€ìš© ìì›ì´ ì—†ìœ¼ë©´ ë‚®ì€ ì ìˆ˜
                safe_print("[WARN] í•„ìš”í•œ ìì›ì´ ìˆì§€ë§Œ ê°€ìš© ìì›ì´ ì—†ìŒ. ë‚®ì€ ì ìˆ˜(0.2) ì‚¬ìš©", logger_name="ReasoningEngine")
                return 0.2
            else:
                safe_print("[WARN] ìì› ì •ë³´ê°€ ì—†ì–´ ê¸°ë³¸ê°’(0.5) ì‚¬ìš©", logger_name="ReasoningEngine")
        except Exception as e:
            from common.utils import safe_print
            safe_print(f"[ERROR] Resource availability extraction failed: {e}", logger_name="ReasoningEngine")
            import traceback
            traceback.print_exc()
        
        return 0.5  # ê¸°ë³¸ê°’

    def _extract_mission_type(self, context: Dict) -> Optional[str]:
        """ì„ë¬´ ìœ í˜• ì¶”ì¶œ (Ontology ê¸°ë°˜)"""
        ontology_manager = context.get("ontology_manager")
        situation_id = context.get("situation_id_raw") or context.get("situation_id")
        
        if not ontology_manager or not situation_id or not hasattr(ontology_manager, 'graph') or ontology_manager.graph is None:
            return None
            
        try:
            from rdflib import URIRef
            from common.utils import safe_print
            ns = ontology_manager.ns
            
            # Mission ì‹ë³„ (resource_availability ë¡œì§ê³¼ ë™ì¼)
            target_mission_nodes = []
            if "MSN" in situation_id:
                # Mission IDì¸ ê²½ìš°
                target_mission_nodes.append(URIRef(ns[f"ì„ë¬´ì •ë³´_{situation_id}"]))
            elif "THR" in situation_id or "THREAT" in situation_id:
                # Threat IDì¸ ê²½ìš° -> ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ Mission ì°¾ê¸°
                normalized_id = situation_id.replace("THREAT", "THR")
                threat_uri_candidates = [
                    URIRef(ns[f"ìœ„í˜‘ìƒí™©_{situation_id}"]), 
                    URIRef(ns[f"ìœ„í˜‘ìƒí™©_{normalized_id}"])
                ]
                
                for threat_node in threat_uri_candidates:
                    # 1. Threat Nodeì—ì„œ ì§ì ‘ ì„ë¬´ ì •ë³´ í™•ì¸ (ìœ„í˜‘ìƒí™©.ê´€ë ¨ì„ë¬´ID ë§¤í•‘)
                    for mission in ontology_manager.graph.objects(threat_node, ns.hasì„ë¬´ì •ë³´):
                        target_mission_nodes.append(mission)
                    
                    # 2. ì‹œë‚˜ë¦¬ì˜¤(Scenario)ë¥¼ í†µí•´ Mission ì°¾ê¸°
                    # ?scenario ns:hasìœ„í˜‘ìƒí™© ?threat_node
                    for scenario in ontology_manager.graph.subjects(ns.hasìœ„í˜‘ìƒí™©, threat_node):
                        # ?scenario ns:hasì„ë¬´ì •ë³´ ?mission
                        for mission in ontology_manager.graph.objects(scenario, ns.hasì„ë¬´ì •ë³´):
                            target_mission_nodes.append(mission)
            
            # Mission Nodeì—ì„œ ì„ë¬´ì¢…ë¥˜/ì„ë¬´ìœ í˜• ì¶”ì¶œ
            for mission_node in target_mission_nodes:
                # ns:ì„ë¬´ì¢…ë¥˜, ns:missionType ë“± ì¡°íšŒ
                for p, o in ontology_manager.graph.predicate_objects(mission_node):
                    pred_name = str(p).split('#')[-1]
                    if pred_name in ['ì„ë¬´ì¢…ë¥˜', 'ì„ë¬´ìœ í˜•', 'missionType']:
                        m_type = str(o)
                        safe_print(f"[INFO] ì˜¨í†¨ë¡œì§€ì—ì„œ ì„ë¬´ ìœ í˜• ì¶”ì¶œ ì„±ê³µ: {m_type}", logger_name="ReasoningEngine")
                        return m_type
                        
        except Exception as e:
            from common.utils import safe_print
            safe_print(f"[WARN] ì„ë¬´ ìœ í˜• ì¶”ì¶œ ì˜¤ë¥˜: {e}", logger_name="ReasoningEngine")
            
        return None

    def _get_unit_properties(self, unit_uri: str, ontology_manager) -> Dict:
        """
        ë¶€ëŒ€/ìì‚°ì˜ ì†ì„± ì¡°íšŒ (í—¬í¼ ë©”ì„œë“œ)
        
        Returns:
            ì†ì„± ë”•ì…”ë„ˆë¦¬ (ë³‘ì¢…, ì œëŒ€, ë¶€ëŒ€ëª…, ìì‚°ì¢…ë¥˜ ë“±)
        """
        props = {}
        try:
            # [REFACTORED] SPARQL ëŒ€ì‹  graph.triples() ì‚¬ìš©
            from rdflib import RDF, RDFS, URIRef
            
            # íƒ€ì… í™•ì¸
            types = [str(o) for s, p, o in ontology_manager.graph.triples((URIRef(unit_uri), RDF.type, None))]
            
            is_asset = any('ì•„êµ°ê°€ìš©ìì‚°' in t for t in types)
            is_unit = any('ì•„êµ°ë¶€ëŒ€í˜„í™©' in t for t in types)
            is_legacy_resource = any('ê°€ìš©ìì›' in t for t in types) or any('AvailableResource' in t for t in types)
            
            node = URIRef(unit_uri)
            ns = ontology_manager.ns
            
            # ëª¨ë“  ë¼ë²¨ ìˆ˜ì§‘ (ì¤‘ë³µ ë¼ë²¨ ì²˜ë¦¬)
            labels = []
            for s, p, o in ontology_manager.graph.triples((node, RDFS.label, None)):
                labels.append(str(o))
            combined_label = ", ".join(labels) if labels else ""
            
            if is_asset:
                props = {'type': 'asset', 'ë¶€ëŒ€ëª…': combined_label, 'ìì‚°ëª…': combined_label}
                # ìì‚°ì¢…ë¥˜
                for s, p, o in ontology_manager.graph.triples((node, ns.ìì‚°ì¢…ë¥˜, None)):
                    props['ìì‚°ì¢…ë¥˜'] = str(o)
            elif is_unit:
                props = {'type': 'unit', 'ë¶€ëŒ€ëª…': combined_label}
                # ë³‘ì¢…
                for s, p, o in ontology_manager.graph.triples((node, ns.ë³‘ì¢…, None)):
                    props['ë³‘ì¢…'] = str(o)
                # ì œëŒ€
                for s, p, o in ontology_manager.graph.triples((node, ns.ì œëŒ€, None)):
                    props['ì œëŒ€'] = str(o)
                # ë¶€ëŒ€ìœ í˜•
                for s, p, o in ontology_manager.graph.triples((node, ns.ë¶€ëŒ€ìœ í˜•, None)):
                    props['ë¶€ëŒ€ìœ í˜•'] = str(o)
                # ì „íˆ¬ë ¥
                for s, p, o in ontology_manager.graph.triples((node, ns.ì „íˆ¬ë ¥, None)):
                    props['ì „íˆ¬ë ¥'] = str(o)
                # ì‚¬ê¸°
                for s, p, o in ontology_manager.graph.triples((node, ns.ì‚¬ê¸°, None)):
                    props['ì‚¬ê¸°'] = str(o)
            elif is_legacy_resource:
                props = {'type': 'legacy_resource', 'ë¶€ëŒ€ëª…': combined_label, 'ë³‘ì¢…': combined_label, 'ìì‚°ì¢…ë¥˜': combined_label}
                # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ ìˆ˜ì§‘
                for s, p, o in ontology_manager.graph.triples((node, ns.ë¹„ê³ , None)):
                    props['ë¹„ê³ '] = str(o)
        except Exception:
            pass
        
        return props
    
    def _match_by_attributes(self, required_concept: str, unit_props: Dict) -> bool:
        """
        ì†ì„± ê¸°ë°˜ ë§¤ì¹­ (ê°œì„ : ë” ìœ ì—°í•œ ë§¤ì¹­ ê·œì¹™)
        """
        if not unit_props:
            return False
        
        concept_lower = required_concept.lower()
        unit_type = str(unit_props.get('ë³‘ì¢…', unit_props.get('ìì‚°ì¢…ë¥˜', ''))).lower()
        unit_level = str(unit_props.get('ì œëŒ€', '')).lower()
        unit_name = str(unit_props.get('ë¶€ëŒ€ëª…', unit_props.get('ìì‚°ëª…', ''))).lower()
        unit_category = str(unit_props.get('ë¶€ëŒ€ìœ í˜•', '')).lower()
        
        # ì „ì²´ í…ìŠ¤íŠ¸ (ëª¨ë“  ì†ì„± ê²°í•©)
        full_text = f"{unit_type} {unit_level} {unit_name} {unit_category}".strip()
        
        # ê°œì„ ëœ ë§¤ì¹­ ê·œì¹™: ì œëŒ€ ì •ë³´ê°€ ì—†ì–´ë„ ë³‘ì¢…ë§Œìœ¼ë¡œ ë§¤ì¹­ ê°€ëŠ¥
        matching_rules = {
            'í¬ë³‘ëŒ€ëŒ€': lambda t, l, n, c, f: ('í¬ë³‘' in t or 'í¬' in t) and (('ëŒ€ëŒ€' in l or 'í¬ë³‘' in l) or l == ''),
            'í¬ë³‘ì—¬ë‹¨': lambda t, l, n, c, f: ('í¬ë³‘' in t or 'í¬' in t) and (('ì—¬ë‹¨' in l or 'í¬ë³‘' in l) or l == ''),
            'ìì£¼í¬ëŒ€ëŒ€': lambda t, l, n, c, f: ('ìì£¼í¬' in t or 'í¬' in t) and (('ëŒ€ëŒ€' in l or 'í¬' in l) or l == ''),
            'ì „ì°¨ëŒ€ëŒ€': lambda t, l, n, c, f: ('ì „ì°¨' in t or 'ê¸°ê°‘' in t) and (('ëŒ€ëŒ€' in l or 'ì „ì°¨' in l or 'ê¸°ê°‘' in l) or l == ''),
            'ë³´ë³‘ì—¬ë‹¨': lambda t, l, n, c, f: ('ë³´ë³‘' in t or 'ë³´' in t) and (('ì—¬ë‹¨' in l or 'ë³´ë³‘' in l) or l == ''),
            'ë³´ë³‘ëŒ€ëŒ€': lambda t, l, n, c, f: ('ë³´ë³‘' in t or 'ë³´' in t) and (('ëŒ€ëŒ€' in l or 'ë³´ë³‘' in l) or l == ''),
            'ê¸°ê³„í™”ë³´ë³‘': lambda t, l, n, c, f: ('ê¸°ê³„í™”' in t or 'ê¸°ê³„í™”ë³´ë³‘' in t or 'ê¸°ë³´' in t) or ('ê¸°ê³„í™”' in n or 'ê¸°ë³´' in n),
            'ê³µë³‘ëŒ€ëŒ€': lambda t, l, n, c, f: ('ê³µë³‘' in t or 'ê³µ' in t) and (('ëŒ€ëŒ€' in l or 'ê³µë³‘' in l) or l == ''),
            'ê¸°ê°‘ëŒ€ëŒ€': lambda t, l, n, c, f: ('ê¸°ê°‘' in t or 'ì „ì°¨' in t or 'ê¸°ê°‘' in n) and (('ëŒ€ëŒ€' in l or 'ê¸°ê°‘' in l) or l == ''),
            'ë°©ê³µëŒ€ëŒ€': lambda t, l, n, c, f: ('ë°©ê³µ' in t or 'ë°©ê³µ' in n) and (('ëŒ€ëŒ€' in l or 'ë°©ê³µ' in l) or l == ''),
            'ëŒ€ì „ì°¨ë¯¸ì‚¬ì¼': lambda t, l, n, c, f: 'ëŒ€ì „ì°¨' in t or 'ë¯¸ì‚¬ì¼' in t or 'ëŒ€ì „ì°¨' in n or 'ë¯¸ì‚¬ì¼' in n or 'ëŒ€ì „ì°¨' in f,
            'ê³µê²©í—¬ê¸°': lambda t, l, n, c, f: 'í—¬ê¸°' in t or 'í—¬ê¸°' in n or 'ê³µê²©í—¬ê¸°' in n or 'í—¬ê¸°' in f,
            'ì „íˆ¬ê¸°': lambda t, l, n, c, f: 'ì „íˆ¬ê¸°' in t or 'ì „íˆ¬ê¸°' in n or 'í•­ê³µ' in t or 'ì „íˆ¬ê¸°' in f,
            'ì „ìì „ë¶€ëŒ€': lambda t, l, n, c, f: 'ì „ìì „' in t or 'ì „ìì „' in n or 'ì „ìì „' in f,
            'ì‚¬ì´ë²„ì „íŒ€': lambda t, l, n, c, f: 'ì‚¬ì´ë²„' in t or 'ì‚¬ì´ë²„' in n or 'ì‚¬ì´ë²„' in f or 'ì „ìì „' in t,
            'psyopsíŒ€': lambda t, l, n, c, f: 'ì‹¬ë¦¬ì „' in t or 'ì‹¬ë¦¬ì „' in n or 'psyo' in f.lower() or 'ì‹¬ë¦¬' in f,
        }
        
        # ê·œì¹™ ê¸°ë°˜ ë§¤ì¹­
        for pattern, match_func in matching_rules.items():
            if pattern in concept_lower:
                if match_func(unit_type, unit_level, unit_name, unit_category, full_text):
                    return True
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶€ë¶„ ë§¤ì¹­ (ê°œì„ : ë” ìœ ì—°í•œ ë§¤ì¹­)
        concept_keywords = set(concept_lower.replace('ëŒ€ëŒ€', '').replace('ì—¬ë‹¨', '').replace('ì‚¬ë‹¨', '').split())
        unit_keywords = set(full_text.split())
        
        # ê³µí†µ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë§¤ì¹­
        if concept_keywords & unit_keywords:
            # í•µì‹¬ í‚¤ì›Œë“œ ë§¤ì¹­ (í¬ë³‘, ë³´ë³‘, ê¸°ê°‘ ë“±)
            core_keywords = {'í¬ë³‘', 'ë³´ë³‘', 'ê¸°ê°‘', 'ê³µë³‘', 'ë°©ê³µ', 'ëŒ€ì „ì°¨', 'í—¬ê¸°', 'ì „íˆ¬ê¸°', 'ì „ìì „', 'ì‚¬ì´ë²„', 'ì‹¬ë¦¬ì „'}
            if concept_keywords & core_keywords & unit_keywords:
                return True
        
        # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
        if (concept_lower in full_text or 
            any(keyword in full_text for keyword in concept_keywords if len(keyword) > 1)):
            return True
        
        return False
    
    def _match_by_hierarchy(self, required_concept: str, unit_props: Dict) -> bool:
        """
        ê³„ì¸µ ë§¤ì¹­ (ê°œì„ ): ë¶€ëŒ€ ê³„ì¸µ êµ¬ì¡° í™œìš©
        ì˜ˆ: í¬ë³‘ëŒ€ëŒ€ -> í¬ë³‘ì—¬ë‹¨ (ìƒìœ„ ê³„ì¸µ), í¬ë³‘ì¤‘ëŒ€ (í•˜ìœ„ ê³„ì¸µ)
        """
        if not unit_props:
            return False
        
        concept_lower = required_concept.lower()
        unit_type = str(unit_props.get('ë³‘ì¢…', unit_props.get('ìì‚°ì¢…ë¥˜', ''))).lower()
        unit_level = str(unit_props.get('ì œëŒ€', '')).lower()
        unit_name = str(unit_props.get('ë¶€ëŒ€ëª…', unit_props.get('ìì‚°ëª…', ''))).lower()
        full_text = f"{unit_type} {unit_level} {unit_name}".strip()
        
        # í™•ì¥ëœ ê³„ì¸µ ë§¤ì¹­ ê·œì¹™
        hierarchy_rules = {
            # í¬ë³‘ ê³„ì¸µ
            'í¬ë³‘ëŒ€ëŒ€': ['í¬ë³‘ì—¬ë‹¨', 'í¬ë³‘ì‚¬ë‹¨', 'í¬ë³‘', 'ìì£¼í¬'],
            'í¬ë³‘ì—¬ë‹¨': ['í¬ë³‘ì‚¬ë‹¨', 'í¬ë³‘', 'í¬ë³‘ëŒ€ëŒ€'],
            'ìì£¼í¬ëŒ€ëŒ€': ['í¬ë³‘ì—¬ë‹¨', 'í¬ë³‘ì‚¬ë‹¨', 'í¬ë³‘', 'ìì£¼í¬'],
            'í¬ë³‘': ['í¬ë³‘ëŒ€ëŒ€', 'í¬ë³‘ì—¬ë‹¨', 'í¬ë³‘ì‚¬ë‹¨', 'ìì£¼í¬ëŒ€ëŒ€'],
            # ë³´ë³‘ ê³„ì¸µ
            'ë³´ë³‘ëŒ€ëŒ€': ['ë³´ë³‘ì—¬ë‹¨', 'ë³´ë³‘ì‚¬ë‹¨', 'ë³´ë³‘', 'ê¸°ê³„í™”ë³´ë³‘'],
            'ë³´ë³‘ì—¬ë‹¨': ['ë³´ë³‘ì‚¬ë‹¨', 'ë³´ë³‘', 'ë³´ë³‘ëŒ€ëŒ€'],
            'ê¸°ê³„í™”ë³´ë³‘': ['ë³´ë³‘ì—¬ë‹¨', 'ë³´ë³‘ì‚¬ë‹¨', 'ë³´ë³‘'],
            'ë³´ë³‘': ['ë³´ë³‘ëŒ€ëŒ€', 'ë³´ë³‘ì—¬ë‹¨', 'ë³´ë³‘ì‚¬ë‹¨', 'ê¸°ê³„í™”ë³´ë³‘'],
            # ê¸°ê°‘ ê³„ì¸µ
            'ê¸°ê°‘ëŒ€ëŒ€': ['ê¸°ê°‘ì—¬ë‹¨', 'ê¸°ê°‘ì‚¬ë‹¨', 'ê¸°ê°‘', 'ì „ì°¨'],
            'ê¸°ê°‘ì—¬ë‹¨': ['ê¸°ê°‘ì‚¬ë‹¨', 'ê¸°ê°‘', 'ì „ì°¨'],
            'ì „ì°¨ëŒ€ëŒ€': ['ê¸°ê°‘ì—¬ë‹¨', 'ê¸°ê°‘ì‚¬ë‹¨', 'ê¸°ê°‘', 'ì „ì°¨'],
            'ê¸°ê°‘': ['ê¸°ê°‘ëŒ€ëŒ€', 'ê¸°ê°‘ì—¬ë‹¨', 'ê¸°ê°‘ì‚¬ë‹¨', 'ì „ì°¨ëŒ€ëŒ€'],
            'ì „ì°¨': ['ê¸°ê°‘ëŒ€ëŒ€', 'ê¸°ê°‘ì—¬ë‹¨', 'ê¸°ê°‘ì‚¬ë‹¨', 'ì „ì°¨ëŒ€ëŒ€'],
        }
        
        for pattern, hierarchy in hierarchy_rules.items():
            if pattern in concept_lower:
                # ê°œë…ì´ ê³„ì¸µì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                if any(h in full_text for h in hierarchy):
                    return True
                # ë¶€ëŒ€ê°€ ê°œë…ì˜ ê³„ì¸µì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                if pattern in full_text:
                    return True
        
        # [NEW] Fallback: ê³„ì¸µ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë¦¬í„°ëŸ´ ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ í™•ì¸
        if concept_lower in full_text:
            return True
            
        return False
    
    def _calculate_semantic_similarity(self, required_concept: str, unit_props: Dict) -> float:
        """
        ì˜ë¯¸ ìœ ì‚¬ë„ ê³„ì‚° (NEW): ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
        í–¥í›„ NLP ëª¨ë¸ë¡œ í™•ì¥ ê°€ëŠ¥
        """
        if not unit_props:
            return 0.0
        
        concept_lower = required_concept.lower()
        unit_type = unit_props.get('ë³‘ì¢…', unit_props.get('ìì‚°ì¢…ë¥˜', '')).lower()
        unit_level = unit_props.get('ì œëŒ€', '').lower()
        unit_name = unit_props.get('ë¶€ëŒ€ëª…', unit_props.get('ìì‚°ëª…', '')).lower()
        
        # ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ
        concept_words = set(concept_lower.split())
        unit_words = set((unit_type + ' ' + unit_level + ' ' + unit_name).split())
        
        # ê³µí†µ í‚¤ì›Œë“œ ë¹„ìœ¨
        common_words = concept_words & unit_words
        if len(concept_words) > 0:
            similarity = len(common_words) / len(concept_words)
        else:
            similarity = 0.0
        
        return similarity
    
    def _match_resource_concept_to_unit_enhanced(
        self, 
        required_concept: str, 
        available_unit_uri: str, 
        ontology_manager,
        debug: bool = False
    ) -> tuple:
        """
        íŒ”ë€í‹°ì–´ ë°©ì‹: ë‹¤ì¸µ ë§¤ì¹­ + ì‹ ë¢°ë„ ì ìˆ˜
        
        Args:
            required_concept: í•„ìš”í•œ ìì› ê°œë…
            available_unit_uri: ê°€ìš© ë¶€ëŒ€/ìì‚° URI
            ontology_manager: ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì €
            debug: ë””ë²„ê¹… ëª¨ë“œ (ìƒì„¸ ë¡œê·¸ ì¶œë ¥)
        
        Returns:
            (ë§¤ì¹­ ì—¬ë¶€, ì‹ ë¢°ë„ ì ìˆ˜ 0.0~1.0)
        """
        match_score = 0.0
        match_reasons = []
        
        # 1. ì§ì ‘ ë§¤ì¹­ (ì‹ ë¢°ë„ 1.0)
        required_concept_clean = required_concept.split('#')[-1] if '#' in required_concept else required_concept
        available_unit_clean = available_unit_uri.split('#')[-1] if '#' in available_unit_uri else available_unit_uri
        
        if required_concept_clean.lower() in available_unit_clean.lower():
            if debug:
                match_reasons.append(f"ì§ì ‘ ë§¤ì¹­: '{required_concept_clean}' in '{available_unit_clean}'")
            return (True, 1.0)
        
        # 2. ì†ì„± ë§¤ì¹­ (ì‹ ë¢°ë„ 0.8)
        unit_props = self._get_unit_properties(available_unit_uri, ontology_manager)
        if unit_props and self._match_by_attributes(required_concept_clean, unit_props):
            match_score = max(match_score, 0.8)
            if debug:
                match_reasons.append(f"ì†ì„± ë§¤ì¹­: unit_props={unit_props}")
        
        # 3. ê³„ì¸µ ë§¤ì¹­ (ì‹ ë¢°ë„ 0.6)
        if unit_props and self._match_by_hierarchy(required_concept_clean, unit_props):
            match_score = max(match_score, 0.6)
            if debug:
                match_reasons.append(f"ê³„ì¸µ ë§¤ì¹­: unit_props={unit_props}")
        
        # 4. ìœ ì‚¬ë„ ë§¤ì¹­ (ì‹ ë¢°ë„ 0.4)
        if unit_props:
            similarity = self._calculate_semantic_similarity(required_concept_clean, unit_props)
            if similarity > 0.5:  # ì„ê³„ê°’ì„ 0.7ì—ì„œ 0.5ë¡œ ë‚®ì¶¤
                match_score = max(match_score, 0.4 * similarity)
                if debug:
                    match_reasons.append(f"ìœ ì‚¬ë„ ë§¤ì¹­: similarity={similarity:.2f}")
        
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ (ğŸ”¥ ìµœì í™”: ì²« ë²ˆì§¸ COAì—ì„œë§Œ ì¶œë ¥)
        # if debug and match_score == 0.0:
        #     from common.utils import safe_print
        #     safe_print(f"[DEBUG] ë§¤ì¹­ ì‹¤íŒ¨: required='{required_concept_clean}', unit='{available_unit_clean}', unit_props={unit_props}", logger_name="ReasoningEngine")
        if debug and match_score > 0.0:
            from common.utils import safe_print
            safe_print(f"[DEBUG] ë§¤ì¹­ ì„±ê³µ: required='{required_concept_clean}', score={match_score:.2f}, reasons={match_reasons}", logger_name="ReasoningEngine")
        
        return (match_score > 0.0, match_score)
    
    def _match_resource_concept_to_unit(self, required_concept: str, available_unit_uri: str, ontology_manager) -> bool:
        """
        ê°œë…ì  ìì›ê³¼ ì‹¤ì œ ë¶€ëŒ€ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” ì•„êµ°ê°€ìš©ìì‚° ë§¤ì¹­
        
        Args:
            required_concept: í•„ìš”í•œ ìì› ê°œë… (ì˜ˆ: "í¬ë³‘ëŒ€ëŒ€", "ë³´ë³‘ì—¬ë‹¨")
            available_unit_uri: ê°€ìš© ë¶€ëŒ€/ìì‚° URI (ì˜ˆ: "ns:ì•„êµ°ë¶€ëŒ€í˜„í™©_FRU006" ë˜ëŠ” "ns:ì•„êµ°ê°€ìš©ìì‚°_AST001")
            ontology_manager: ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì €
        
        Returns:
            ë§¤ì¹­ ì—¬ë¶€ (True/False)
        """
        try:
            # ğŸ”¥ ê°œì„ : ì•„êµ°ê°€ìš©ìì‚°ê³¼ ì•„êµ°ë¶€ëŒ€í˜„í™© ëª¨ë‘ ì§€ì›
            # ë¨¼ì € íƒ€ì… í™•ì¸
            from rdflib import RDF, URIRef
            node = URIRef(available_unit_uri)
            types = [str(o) for o in ontology_manager.graph.objects(node, RDF.type)]
            
            is_asset = any('ì•„êµ°ê°€ìš©ìì‚°' in t for t in types)
            is_unit = any('ì•„êµ°ë¶€ëŒ€í˜„í™©' in t for t in types)
            is_allocation = any('ì„ë¬´ë³„_ìì›í• ë‹¹' in t for t in types)
            
            # 1. ì„ë¬´ë³„_ìì›í• ë‹¹ì¸ ê²½ìš°: tactical_role ì†ì„± í™œìš© (ìµœìš°ì„ )
            if is_allocation:
                ns = ontology_manager.ns
                tactical_role = ""
                for o in ontology_manager.graph.objects(node, ns.tactical_role):
                    tactical_role = str(o).lower()
                
                if tactical_role:
                    concept_lower = required_concept.lower()
                    if concept_lower in tactical_role or tactical_role in concept_lower:
                        return True
                    
                    # ì „ìˆ ì  ì—­í•  ê¸°ë°˜ ë§¤ì¹­ (ì˜ˆ: "í™”ë ¥ì§€ì›" -> "í¬ë³‘")
                    role_matching = {
                        'í™”ë ¥ì§€ì›': ['í¬ë³‘', 'ê³µì¶©', 'í•­ê³µ', 'í™”ë ¥'],
                        'ì¶©ê²©êµ°': ['ê¸°ê°‘', 'ì „ì°¨', 'ê¸°ê³„í™”'],
                        'ê¸°ë™ì°¨ë‹¨': ['ë³´ë³‘', 'ê³µë³‘', 'ì°¨ë‹¨'],
                        'ì •ì°°ê°ì‹œ': ['ì •ì°°', 'ë“œë¡ ', 'ê°ì‹œ']
                    }
                    for role, keywords in role_matching.items():
                        if role in tactical_role:
                            if any(kw in concept_lower for kw in keywords):
                                return True

            # 2. ì•„êµ°ê°€ìš©ìì‚°ì¸ ê²½ìš°: ìì‚°ì¢…ë¥˜ ì†ì„± í™œìš©
            if is_asset:
                ns = ontology_manager.ns
                from rdflib import RDFS
                asset_type = ""
                for o in ontology_manager.graph.objects(node, ns.ìì‚°ì¢…ë¥˜):
                    asset_type = str(o).lower()
                asset_name = ""
                for o in ontology_manager.graph.objects(node, RDFS.label):
                    asset_name = str(o).lower()
                
                if asset_type or asset_name:
                    concept_lower = required_concept.lower()
                    
                    # ìì‚°ì¢…ë¥˜ ê¸°ë°˜ ë§¤ì¹­ ê·œì¹™
                    asset_matching_rules = {
                        'í¬ë³‘ëŒ€ëŒ€': lambda t, n: 'í¬ë³‘' in t or 'í¬' in t or 'í¬ë³‘' in n,
                        'í¬ë³‘ì—¬ë‹¨': lambda t, n: 'í¬ë³‘' in t or 'í¬' in t or 'í¬ë³‘' in n,
                        'ë³´ë³‘ì—¬ë‹¨': lambda t, n: 'ë³´ë³‘' in t or 'ë³´' in t or 'ë³´ë³‘' in n,
                        'ë³´ë³‘ëŒ€ëŒ€': lambda t, n: 'ë³´ë³‘' in t or 'ë³´' in t or 'ë³´ë³‘' in n,
                        'ê³µë³‘ëŒ€ëŒ€': lambda t, n: 'ê³µë³‘' in t or 'ê³µ' in t or 'ê³µë³‘' in n,
                        'ê¸°ê°‘ëŒ€ëŒ€': lambda t, n: 'ê¸°ê°‘' in t or 'ì „ì°¨' in t or 'ê¸°ê°‘' in n,
                        'ë°©ê³µëŒ€ëŒ€': lambda t, n: 'ë°©ê³µ' in t or 'ë°©ê³µ' in n,
                        'ëŒ€ì „ì°¨ë¯¸ì‚¬ì¼': lambda t, n: 'ëŒ€ì „ì°¨' in t or 'ë¯¸ì‚¬ì¼' in t or 'ëŒ€ì „ì°¨' in n or 'ë¯¸ì‚¬ì¼' in n,
                        'ê³µê²©í—¬ê¸°': lambda t, n: 'í—¬ê¸°' in t or 'í—¬ê¸°' in n or 'ê³µê²©í—¬ê¸°' in n,
                        'ì „íˆ¬ê¸°': lambda t, n: 'ì „íˆ¬ê¸°' in t or 'ì „íˆ¬ê¸°' in n or 'í•­ê³µ' in t,
                    }
                    
                    # ê·œì¹™ ê¸°ë°˜ ë§¤ì¹­
                    for concept_pattern, match_func in asset_matching_rules.items():
                        if concept_pattern in concept_lower:
                            if match_func(asset_type, asset_name):
                                return True
                    
                    # ë¶€ë¶„ ë§¤ì¹­
                    if (required_concept.lower() in asset_type or 
                        required_concept.lower() in asset_name or
                        any(keyword in asset_type for keyword in required_concept.lower().split())):
                        return True
            
            # ì•„êµ°ë¶€ëŒ€í˜„í™©ì¸ ê²½ìš°: ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            if is_unit:
                ns = ontology_manager.ns
                from rdflib import RDFS
                unit_type = ""
                for o in ontology_manager.graph.objects(node, ns.ë³‘ì¢…):
                    unit_type = str(o).lower()
                unit_level = ""
                for o in ontology_manager.graph.objects(node, ns.ì œëŒ€):
                    unit_level = str(o).lower()
                unit_name = ""
                for o in ontology_manager.graph.objects(node, RDFS.label):
                    unit_name = str(o).lower()
                unit_category = ""
                for o in ontology_manager.graph.objects(node, ns.ë¶€ëŒ€ìœ í˜•):
                    unit_category = str(o).lower()
                
                if unit_type or unit_level or unit_name or unit_category:
                    concept_lower = required_concept.lower()
                    
                    # ë§¤ì¹­ ê·œì¹™ ì •ì˜
                    matching_rules = {
                        'í¬ë³‘ëŒ€ëŒ€': lambda t, l, n, c: ('í¬ë³‘' in t or 'í¬' in t) and ('ëŒ€ëŒ€' in l or 'í¬ë³‘' in l or 'í¬' in l),
                        'í¬ë³‘ì—¬ë‹¨': lambda t, l, n, c: ('í¬ë³‘' in t or 'í¬' in t) and ('ì—¬ë‹¨' in l or 'í¬ë³‘' in l),
                        'ë³´ë³‘ì—¬ë‹¨': lambda t, l, n, c: ('ë³´ë³‘' in t or 'ë³´' in t) and ('ì—¬ë‹¨' in l or 'ë³´ë³‘' in l),
                        'ë³´ë³‘ëŒ€ëŒ€': lambda t, l, n, c: ('ë³´ë³‘' in t or 'ë³´' in t) and ('ëŒ€ëŒ€' in l or 'ë³´ë³‘' in l),
                        'ê³µë³‘ëŒ€ëŒ€': lambda t, l, n, c: ('ê³µë³‘' in t or 'ê³µ' in t) and ('ëŒ€ëŒ€' in l or 'ê³µë³‘' in l),
                        'ê¸°ê°‘ëŒ€ëŒ€': lambda t, l, n, c: ('ê¸°ê°‘' in t or 'ì „ì°¨' in t or 'ê¸°ê°‘' in n) and ('ëŒ€ëŒ€' in l or 'ê¸°ê°‘' in l),
                        'ë°©ê³µëŒ€ëŒ€': lambda t, l, n, c: ('ë°©ê³µ' in t or 'ë°©ê³µ' in n) and ('ëŒ€ëŒ€' in l or 'ë°©ê³µ' in l),
                        'ëŒ€ì „ì°¨ë¯¸ì‚¬ì¼': lambda t, l, n, c: 'ëŒ€ì „ì°¨' in t or 'ë¯¸ì‚¬ì¼' in t or 'ëŒ€ì „ì°¨' in n or 'ë¯¸ì‚¬ì¼' in n,
                        'ê³µê²©í—¬ê¸°': lambda t, l, n, c: 'í—¬ê¸°' in t or 'í—¬ê¸°' in n or 'ê³µê²©í—¬ê¸°' in n,
                        'ì „íˆ¬ê¸°': lambda t, l, n, c: 'ì „íˆ¬ê¸°' in t or 'ì „íˆ¬ê¸°' in n or 'í•­ê³µ' in t,
                    }
                    
                    # ê·œì¹™ ê¸°ë°˜ ë§¤ì¹­
                    for concept_pattern, match_func in matching_rules.items():
                        if concept_pattern in concept_lower:
                            if match_func(unit_type, unit_level, unit_name, unit_category):
                                return True
                    
                    # ë¶€ë¶„ ë§¤ì¹­ (ë°±ì—…)
                    if (required_concept.lower() in unit_type or 
                        required_concept.lower() in unit_level or 
                        required_concept.lower() in unit_name or
                        any(keyword in unit_type for keyword in required_concept.lower().split()) or
                        any(keyword in unit_level for keyword in required_concept.lower().split())):
                        return True
            
            return False
            
        except Exception as e:
            # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ False ë°˜í™˜ (ì—ëŸ¬ ë¡œê·¸ëŠ” ìƒìœ„ì—ì„œ ì²˜ë¦¬)
            return False
    
    def _calculate_resource_quality(self, available_resources: List[str], ontology_manager) -> float:
        """
        ìì› í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì „íˆ¬ë ¥, ì‚¬ê¸°, ìƒíƒœ ë°˜ì˜)
        íŒ”ë€í‹°ì–´ ë°©ì‹: ìì›ì˜ í’ˆì§ˆì„ ë°˜ì˜í•˜ì—¬ ë§¤ì¹­ ì ìˆ˜ ì¡°ì •
        """
        if not available_resources or not ontology_manager:
            return 0.5  # ì •ë³´ ì—†ìœ¼ë©´ ì¤‘ë¦½
        
        total_quality = 0.0
        count = 0
        
        for resource_uri in available_resources:
            try:
                # ì „íˆ¬ë ¥ ì¡°íšŒ
                from rdflib import URIRef
                node = URIRef(resource_uri)
                ns = ontology_manager.ns
                combat_power_list = [str(o) for o in ontology_manager.graph.objects(node, ns.ì „íˆ¬ë ¥)]
                
                # ì‚¬ê¸° ì¡°íšŒ
                morale_list = [str(o) for o in ontology_manager.graph.objects(node, ns.ì‚¬ê¸°)]
                
                # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì „íˆ¬ë ¥ 70%, ì‚¬ê¸° 30%)
                power_score = 0.5
                if combat_power_list:
                    try:
                        power_val = float(combat_power_list[0])
                        power_score = power_val / 100.0 if power_val <= 100 else 1.0
                    except (ValueError, TypeError):
                        pass
                
                morale_score = 0.5
                if morale_list:
                    try:
                        morale_val = float(morale_list[0])
                        morale_score = morale_val / 100.0 if morale_val <= 100 else 1.0
                    except (ValueError, TypeError):
                        pass
                
                quality = (power_score * 0.7) + (morale_score * 0.3)
                total_quality += quality
                count += 1
            except Exception:
                # ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                total_quality += 0.5
                count += 1
        
        return total_quality / count if count > 0 else 0.5
    
    def _find_alternative_resources(self, required_resource_uri: str, context: Dict) -> List[str]:
        """
        ëŒ€ì²´ ìì› ì°¾ê¸° (íŒ”ë€í‹°ì–´ ë°©ì‹)
        
        ì˜ˆ: í¬ë³‘ëŒ€ëŒ€ -> í¬ë³‘ì—¬ë‹¨, í¬ë³‘ì‚¬ë‹¨ (ìƒìœ„ ê³„ì¸µ)
        ì˜ˆ: ë³´ë³‘ì—¬ë‹¨ -> ë³´ë³‘ëŒ€ëŒ€, ë³´ë³‘ì‚¬ë‹¨ (ê³„ì¸µ ë‚´)
        """
        ontology_manager = context.get('ontology_manager')
        if not ontology_manager:
            return []
        
        # í•„ìš”í•œ ìì›ì˜ ê°œë… ì¶”ì¶œ
        required_concept = required_resource_uri.split('#')[-1] if '#' in required_resource_uri else required_resource_uri
        required_concept_lower = required_concept.lower()
        
        alternatives = []
        
        # ê³„ì¸µ ê¸°ë°˜ ëŒ€ì²´ ìì› ì°¾ê¸°
        hierarchy_map = {
            'í¬ë³‘ëŒ€ëŒ€': ['í¬ë³‘ì—¬ë‹¨', 'í¬ë³‘ì‚¬ë‹¨', 'í¬ë³‘'],
            'í¬ë³‘ì—¬ë‹¨': ['í¬ë³‘ëŒ€ëŒ€', 'í¬ë³‘ì‚¬ë‹¨', 'í¬ë³‘'],
            'í¬ë³‘': ['í¬ë³‘ëŒ€ëŒ€', 'í¬ë³‘ì—¬ë‹¨', 'í¬ë³‘ì‚¬ë‹¨'],
            'ë³´ë³‘ëŒ€ëŒ€': ['ë³´ë³‘ì—¬ë‹¨', 'ë³´ë³‘ì‚¬ë‹¨', 'ë³´ë³‘'],
            'ë³´ë³‘ì—¬ë‹¨': ['ë³´ë³‘ëŒ€ëŒ€', 'ë³´ë³‘ì‚¬ë‹¨', 'ë³´ë³‘'],
            'ë³´ë³‘': ['ë³´ë³‘ëŒ€ëŒ€', 'ë³´ë³‘ì—¬ë‹¨', 'ë³´ë³‘ì‚¬ë‹¨'],
            'ê¸°ê°‘ëŒ€ëŒ€': ['ê¸°ê°‘ì—¬ë‹¨', 'ê¸°ê°‘ì‚¬ë‹¨', 'ê¸°ê°‘'],
            'ê¸°ê°‘ì—¬ë‹¨': ['ê¸°ê°‘ëŒ€ëŒ€', 'ê¸°ê°‘ì‚¬ë‹¨', 'ê¸°ê°‘'],
            'ê¸°ê°‘': ['ê¸°ê°‘ëŒ€ëŒ€', 'ê¸°ê°‘ì—¬ë‹¨', 'ê¸°ê°‘ì‚¬ë‹¨'],
            'ê³µë³‘ëŒ€ëŒ€': ['ê³µë³‘ì—¬ë‹¨', 'ê³µë³‘ì‚¬ë‹¨', 'ê³µë³‘'],
            'ë°©ê³µëŒ€ëŒ€': ['ë°©ê³µì—¬ë‹¨', 'ë°©ê³µì‚¬ë‹¨', 'ë°©ê³µ'],
        }
        
        # ëŒ€ì²´ ìì› ê°œë… ì°¾ê¸°
        alt_concepts = []
        for pattern, hierarchy in hierarchy_map.items():
            if pattern in required_concept_lower:
                alt_concepts.extend(hierarchy)
                break
        
        # ëŒ€ì²´ ìì› URI ì°¾ê¸°
        if alt_concepts:
            for alt_concept in alt_concepts:
                # ì˜¨í†¨ë¡œì§€ì—ì„œ ëŒ€ì²´ ìì› ê²€ìƒ‰
                try:
                    from rdflib import RDF, URIRef
                    ns = ontology_manager.ns
                    # ì•„êµ°ë¶€ëŒ€í˜„í™© ë° ì•„êµ°ê°€ìš©ìì‚° íƒìƒ‰
                    found_resources = []
                    
                    # ns:ì•„êµ°ë¶€ëŒ€í˜„í™© íƒ€ì…ì¸ ìì‚° ì¤‘ ë³‘ì¢…ì´ alt_conceptì„ í¬í•¨í•˜ëŠ” ê²ƒ
                    for s, p, o in ontology_manager.graph.triples((None, RDF.type, ns.ì•„êµ°ë¶€ëŒ€í˜„í™©)):
                        for type_val in ontology_manager.graph.objects(s, ns.ë³‘ì¢…):
                            if alt_concept.lower() in str(type_val).lower():
                                found_resources.append(str(s))
                    
                    # ns:ì•„êµ°ê°€ìš©ìì‚° íƒ€ì…ì¸ ìì‚° ì¤‘ ìì‚°ì¢…ë¥˜ê°€ alt_conceptì„ í¬í•¨í•˜ëŠ” ê²ƒ
                    for s, p, o in ontology_manager.graph.triples((None, RDF.type, ns.ì•„êµ°ê°€ìš©ìì‚°)):
                        for type_val in ontology_manager.graph.objects(s, ns.ìì‚°ì¢…ë¥˜):
                            if alt_concept.lower() in str(type_val).lower():
                                found_resources.append(str(s))
                    
                    for resource_uri in found_resources[:10]:
                        if resource_uri and resource_uri not in alternatives:
                            alternatives.append(resource_uri)
                except Exception:
                    pass
        
        return alternatives
    
    def _extract_asset_capability(self, context: Dict) -> float:
        """ë°©ì–´ ìì‚° ëŠ¥ë ¥ ì¶”ì¶œ"""
        defense_assets = context.get("defense_assets", [])
        graph = context.get("graph")
        ontology_manager = context.get("ontology_manager")
        
        if defense_assets:
            if isinstance(defense_assets, list) and len(defense_assets) > 0:
                # ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê·  ê³„ì‚°
                firepowers = []
                for asset in defense_assets:
                    if isinstance(asset, dict):
                        if 'firepower' in asset:
                            firepowers.append(float(asset['firepower']))
                    elif isinstance(asset, (int, float)):
                        firepowers.append(float(asset))
                
                if firepowers:
                    avg = sum(firepowers) / len(firepowers)
                    return min(1.0, avg / 100.0)
        
        # ê·¸ë˜í”„ì—ì„œ ì•„êµ° ì •ë³´ ì¶”ì¶œ
        if graph is not None and ontology_manager is not None:
            try:
                ns = ontology_manager.ns
                firepowers = []
                morales = []
                
                # ëª¨ë“  ìœ ë‹›ì˜ ì „íˆ¬ë ¥ê³¼ ì‚¬ê¸° ì¡°íšŒ
                for s, p, o in graph.triples((None, ns.ì „íˆ¬ë ¥, None)):
                    try:
                        firepowers.append(float(str(o)))
                    except:
                        pass
                for s, p, o in graph.triples((None, ns.ì‚¬ê¸°, None)):
                    try:
                        morales.append(float(str(o)))
                    except:
                        pass
                
                if firepowers:
                    avg_firepower = sum(firepowers) / len(firepowers)
                    return min(1.0, avg_firepower / 100.0)
                elif morales:
                    avg_morale = sum(morales) / len(morales)
                    return min(1.0, avg_morale / 100.0)
            except Exception:
                pass
        
        return 0.5  # ê¸°ë³¸ê°’
    
    def _extract_environment_fit(self, context: Dict) -> float:
        """í™˜ê²½ ì í•©ì„± ì¶”ì¶œ (ê¸°ìƒìƒí™©, ì§€í˜• ì •ë³´ í™œìš©, ë¡œê¹… ë° ê²€ì¦ ê°•í™”)"""
        ontology_manager = context.get("ontology_manager")
        situation_id = context.get("situation_id")
        coa_uri = context.get("coa_uri")  # ì‹¤ì œ COA URI ì‚¬ìš©
        
        # ì§ì ‘ ì œê³µëœ í™˜ê²½ ì í•©ì„± ì‚¬ìš©
        if "environment_fit" in context:
            return float(context["environment_fit"])
        
        if not ontology_manager or not hasattr(ontology_manager, 'execute_template_query'):
            from common.utils import safe_print
            safe_print("[WARN] OntologyManager ë˜ëŠ” execute_template_query ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’(0.5) ì‚¬ìš©", logger_name="ReasoningEngine")
            return 0.5
        
        if not situation_id:
            situation_id = "THREAT001"  # ê¸°ë³¸ê°’
            from common.utils import safe_print
            safe_print(f"[INFO] situation_idê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {situation_id}", logger_name="ReasoningEngine")
        
        try:
            from common.utils import safe_print
            if context.get('is_first_coa', False):
                safe_print(f"[INFO] í™˜ê²½ ì í•©ì„± ì¡°íšŒ: COA={coa_uri}, Situation={situation_id}", logger_name="ReasoningEngine")
            
            # URI íŒŒì‹±: ì „ì²´ URIê°€ ì „ë‹¬ë˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, IDë§Œ ì „ë‹¬ë˜ë©´ URI ìƒì„±
            if situation_id.startswith("http://"):
                situation_uri_for_query = situation_id
            else:
                # IDë§Œ ì „ë‹¬ëœ ê²½ìš° URI ìƒì„±
                situation_uri_for_query = f"http://coa-agent-platform.org/ontology#{situation_id}"
            
            # 1. ìœ„í˜‘ìƒí™©ì˜ ê¸°ìƒìƒí™© ì¡°íšŒ (ê°œì„ : ìœ„ì¹˜ ê¸°ë°˜ ì¡°íšŒ)
            from rdflib import RDF, URIRef
            ns = ontology_manager.ns
            situation_node = URIRef(situation_uri_for_query)
            
            weather_results = []
            # ë¨¼ì € ì§ì ‘ ì—°ê²°ëœ í™˜ê²½ ì •ë³´ ì¡°íšŒ ì‹œë„ (ns:occursInEnvironment)
            for weather_node in ontology_manager.graph.objects(situation_node, ns.occursInEnvironment):
                weather_data = {'weather': str(weather_node)}
                for state in ontology_manager.graph.objects(weather_node, ns.ìƒíƒœ):
                    weather_data['weather_state'] = str(state)
                weather_results.append(weather_data)
            
            # ì§ì ‘ ì—°ê²°ì´ ì—†ìœ¼ë©´ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ê¸°ìƒìƒí™© í…Œì´ë¸” ì¡°íšŒ
            if not weather_results:
                for location_node in ontology_manager.graph.objects(situation_node, ns.hasì§€í˜•ì…€):
                    # ns:hasì§€í˜•ì…€ì´ location_nodeì¸ ê¸°ìƒìƒí™©(ns:ê¸°ìƒìƒí™©) ì°¾ê¸°
                    for s, p, o in ontology_manager.graph.triples((None, ns.hasì§€í˜•ì…€, location_node)):
                        if (s, RDF.type, ns.ê¸°ìƒìƒí™©) in ontology_manager.graph:
                            weather_data = {'weather': str(s)}
                            for state in ontology_manager.graph.objects(s, ns.ê¸°ìƒìœ í˜•):
                                weather_data['weather_state'] = str(state)
                            weather_results.append(weather_data)
            # ğŸ”¥ ë¡œê·¸ ìµœì í™”: ë°˜ë³µë˜ëŠ” DEBUG ë¡œê·¸ ì œê±° (ê° COAë§ˆë‹¤ í˜¸ì¶œë˜ë¯€ë¡œ)
            # safe_print(f"[DEBUG] ê¸°ìƒìƒí™© ì¡°íšŒ ê²°ê³¼: {len(weather_results)}ê°œ", logger_name="ReasoningEngine")
            
            # 2. COAì˜ í™˜ê²½ í˜¸í™˜ì„± ì¡°íšŒ
            if coa_uri:
                # URI íŒŒì‹±: ì „ì²´ URIê°€ ì „ë‹¬ë˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, IDë§Œ ì „ë‹¬ë˜ë©´ URI ìƒì„±
                if coa_uri.startswith("http://"):
                    coa_uri_for_query = coa_uri
                else:
                    # IDë§Œ ì „ë‹¬ëœ ê²½ìš° URI ìƒì„±
                    coa_uri_for_query = f"http://coa-agent-platform.org/ontology#{coa_uri}"
                
                coa_node = URIRef(coa_uri_for_query)
                compatibility_results = []
                for env_node in ontology_manager.graph.objects(coa_node, ns.compatibleWith):
                    comp_data = {'env': str(env_node)}
                    for score in ontology_manager.graph.objects(coa_node, ns.compatibilityScore):
                        comp_data['compatibility'] = str(score)
                    compatibility_results.append(comp_data)
                # ğŸ”¥ ë¡œê·¸ ìµœì í™”: ë°˜ë³µë˜ëŠ” DEBUG ë¡œê·¸ ì œê±° (ê° COAë§ˆë‹¤ í˜¸ì¶œë˜ë¯€ë¡œ)
                # safe_print(f"[DEBUG] í™˜ê²½ í˜¸í™˜ì„± ì¡°íšŒ ê²°ê³¼: {len(compatibility_results)}ê°œ", logger_name="ReasoningEngine")
                
                # 3. íŒ”ë€í‹°ì–´ ë°©ì‹: ë‹¤ì°¨ì› í™˜ê²½ í‰ê°€ (ê°œì„ )
                # í˜„ì¬ í™˜ê²½ ì •ë³´ ì¡°íšŒ
                current_env = self._get_current_environment(situation_uri_for_query, ontology_manager)
                
                # [NEW] ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ì œê³µëœ í™˜ê²½ ì •ë³´ë¡œ ì˜¤ë²„ë¼ì´ë“œ (UI ì…ë ¥ ìš°ì„ )
                if 'weather' in context and context['weather']:
                    current_env['ê¸°ìƒ'] = context['weather']
                    if context.get('is_first_coa', False):
                        safe_print(f"[INFO] í™˜ê²½ ì •ë³´ ì˜¤ë²„ë¼ì´ë“œ: ê¸°ìƒ -> {context['weather']}", logger_name="ReasoningEngine")
                if 'terrain' in context and context['terrain']:
                    current_env['ì§€í˜•'] = context['terrain']
                    if context.get('is_first_coa', False):
                        safe_print(f"[INFO] í™˜ê²½ ì •ë³´ ì˜¤ë²„ë¼ì´ë“œ: ì§€í˜• -> {context['terrain']}", logger_name="ReasoningEngine")
                if 'time_of_day' in context and context['time_of_day']:
                    current_env['ì‹œê°„'] = context['time_of_day']
                
                # ê¸°ìƒ ìœ í˜• ì¶”ì¶œ (ê¸°ìƒìœ í˜• ì»¬ëŸ¼ ì‚¬ìš©)
                weather_types = []
                for w in weather_results:
                    weather_state = w.get('weather_state', '')
                    if weather_state:
                        weather_types.append(str(weather_state))
                    # weather_stateê°€ ì—†ìœ¼ë©´ weather URIì—ì„œ ì¶”ì¶œ
                    weather_uri = str(w.get('weather', ''))
                    if weather_uri and not weather_state:
                        weather_label = weather_uri.split('#')[-1] if '#' in weather_uri else weather_uri
                        weather_types.append(weather_label)
                
                if weather_types:
                    current_env['ê¸°ìƒ'] = weather_types[0]  # ì²« ë²ˆì§¸ ê¸°ìƒ ìœ í˜• ì‚¬ìš©
                
                # í™˜ê²½ ì ìˆ˜ ê³„ì‚° (ê¸°ë³¸ê°’ 0.5)
                score = 0.5
                match_found = False
                
                # í˜¸í™˜ í™˜ê²½ ë§¤ì¹­ (+0.2 per match, ìµœëŒ€ +0.4)
                compatible_envs = []
                for c in compatibility_results:
                    env_uri = c.get('env', '')
                    if env_uri:
                        # URIì—ì„œ í™˜ê²½ ì´ë¦„ ì¶”ì¶œ
                        env_name = str(env_uri).split('#')[-1] if '#' in str(env_uri) else str(env_uri)
                        compatible_envs.append(env_name.lower())
                
                compatible_match_count = 0
                for env in compatible_envs:
                    env_lower = env
                    # í˜„ì¬ í™˜ê²½ê³¼ ë§¤ì¹­ í™•ì¸ (ë” ìœ ì—°í•œ ë§¤ì¹­)
                    for env_key, env_value in current_env.items():
                        if env_value and env_lower in str(env_value).lower():
                            score += 0.2
                            compatible_match_count += 1
                            match_found = True
                            if context.get('is_first_coa', False):
                                safe_print(f"[INFO] í™˜ê²½ í˜¸í™˜ ë§¤ì¹­: '{env}' <-> '{env_value}' (+0.2)", logger_name="ReasoningEngine")
                            break
                    # ê¸°ìƒ ìœ í˜•ê³¼ ì§ì ‘ ë§¤ì¹­
                    if weather_types and any(env_lower in wt.lower() for wt in weather_types):
                        score += 0.2
                        compatible_match_count += 1
                        match_found = True
                        if context.get('is_first_coa', False):
                            safe_print(f"[INFO] í™˜ê²½ í˜¸í™˜ ë§¤ì¹­: '{env}' <-> ê¸°ìƒ '{weather_types[0]}' (+0.2)", logger_name="ReasoningEngine")
                
                # ìµœëŒ€ +0.4ë¡œ ì œí•œ
                if compatible_match_count > 2:
                    score = 0.5 + 0.4
                else:
                    score = min(1.0, score)
                
                # ë¹„í˜¸í™˜ í™˜ê²½ í™•ì¸
                incompatible_results = []
                for env_node in ontology_manager.graph.objects(coa_node, ns.incompatibleWith):
                    incompatible_results.append({'env': str(env_node)})
                incompatible_envs = []
                for i in incompatible_results:
                    env_uri = i.get('env', '')
                    if env_uri:
                        env_name = str(env_uri).split('#')[-1] if '#' in str(env_uri) else str(env_uri)
                        incompatible_envs.append(env_name.lower())
                
                # ë¹„í˜¸í™˜ í™˜ê²½ ë§¤ì¹­ (-0.3 per match, ìµœëŒ€ -0.6)
                incompatible_match_count = 0
                for env in incompatible_envs:
                    env_lower = env
                    # í˜„ì¬ í™˜ê²½ê³¼ ë§¤ì¹­ í™•ì¸
                    for env_key, env_value in current_env.items():
                        if env_value and env_lower in str(env_value).lower():
                            score -= 0.3
                            incompatible_match_count += 1
                            match_found = True
                            if context.get('is_first_coa', False):
                                safe_print(f"[INFO] í™˜ê²½ ë¹„í˜¸í™˜ ë§¤ì¹­: '{env}' <-> '{env_value}' (-0.3)", logger_name="ReasoningEngine")
                            break
                    # ê¸°ìƒ ìœ í˜•ê³¼ ì§ì ‘ ë§¤ì¹­
                    if weather_types and any(env_lower in wt.lower() for wt in weather_types):
                        score -= 0.3
                        incompatible_match_count += 1
                        match_found = True
                        if context.get('is_first_coa', False):
                            safe_print(f"[INFO] í™˜ê²½ ë¹„í˜¸í™˜ ë§¤ì¹­: '{env}' <-> ê¸°ìƒ '{weather_types[0]}' (-0.3)", logger_name="ReasoningEngine")
                
                # ìµœëŒ€ -0.6ë¡œ ì œí•œ
                if incompatible_match_count > 2:
                    score = max(0.0, score - 0.6)
                
                # ê¸°ìƒ ì •ë³´ê°€ ìˆì§€ë§Œ COA í˜¸í™˜ì„± ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬
                if not match_found and weather_types:
                    # ì•…ì²œí›„, ì•ˆê°œëŠ” ë‚®ì€ ì ìˆ˜, ë§‘ìŒì€ ë†’ì€ ì ìˆ˜
                    if any('ì•…ì²œí›„' in wt or 'ì•ˆê°œ' in wt for wt in weather_types):
                        score = 0.4
                        if context.get('is_first_coa', False):
                            safe_print(f"[INFO] ê¸°ìƒ ì •ë³´ ê¸°ë°˜ ì ìˆ˜: ì•…ì²œí›„/ì•ˆê°œ â†’ 0.4", logger_name="ReasoningEngine")
                    elif any('ì•¼ê°„' in wt for wt in weather_types):
                        score = 0.6
                        if context.get('is_first_coa', False):
                            safe_print(f"[INFO] ê¸°ìƒ ì •ë³´ ê¸°ë°˜ ì ìˆ˜: ì•¼ê°„ â†’ 0.6", logger_name="ReasoningEngine")
                    elif any('ë§‘ìŒ' in wt for wt in weather_types):
                        score = 0.8
                        if context.get('is_first_coa', False):
                            safe_print(f"[INFO] ê¸°ìƒ ì •ë³´ ê¸°ë°˜ ì ìˆ˜: ë§‘ìŒ â†’ 0.8", logger_name="ReasoningEngine")
                
                # ìµœì¢… ì ìˆ˜ ë°˜í™˜
                return min(1.0, max(0.0, score))
            else:
                # COA URIê°€ ì—†ìœ¼ë©´ í™˜ê²½ ê¸°ë°˜ ì í•© COA ì¡°íšŒ
                from rdflib import URIRef
                situation_node = URIRef(situation_id if situation_id.startswith('http') else f"http://coa-agent-platform.org/ontology#{situation_id}")
                ns = ontology_manager.ns
                
                # find_coas_by_environment í…œí”Œë¦¿ ë¡œì§ êµ¬í˜„
                # ?situation ns:occursInEnvironment ?weather .
                # ?situation ns:occursInEnvironment ?terrain .
                # ?coa ns:compatibleWith ?weather .
                # ?coa ns:compatibleWith ?terrain .
                env_nodes = list(ontology_manager.graph.objects(situation_node, ns.occursInEnvironment))
                suitable_coas = set()
                if env_nodes:
                    # ëª¨ë“  í™˜ê²½ ìš”ì†Œì— í˜¸í™˜ë˜ëŠ” COA ì°¾ê¸° (ë‹¨ìˆœí™”: í•˜ë‚˜ë¼ë„ í˜¸í™˜ë˜ë©´ í¬í•¨)
                    for env in env_nodes:
                        for coa_node, p, o in ontology_manager.graph.triples((None, ns.compatibleWith, env)):
                            suitable_coas.add(coa_node)
                
                # í™˜ê²½ í˜¸í™˜ COAê°€ ìˆìœ¼ë©´ 1.0, ì—†ìœ¼ë©´ 0.5
                return 1.0 if suitable_coas else 0.5
        except Exception as e:
            from common.utils import safe_print
            safe_print(f"[WARN] Environment fit extraction failed: {e}", logger_name="ReasoningEngine")
            import traceback
            traceback.print_exc()
        
        return 0.5  # ê¸°ë³¸ê°’
    
    def _get_current_environment(self, situation_uri: str, ontology_manager) -> Dict:
        """
        í˜„ì¬ í™˜ê²½ ì •ë³´ ì¡°íšŒ (ê¸°ìƒìƒí™© í…Œì´ë¸” í™œìš©)
        íŒ”ë€í‹°ì–´ ë°©ì‹: ë‹¤ì°¨ì› í™˜ê²½ ì •ë³´ ìˆ˜ì§‘
        """
        env_info = {}
        
        try:
            # ìœ„í˜‘ìƒí™©ì˜ ì§€í˜•ì…€ ì¡°íšŒ
            from rdflib import URIRef
            ns = ontology_manager.ns
            situation_node = URIRef(situation_uri)
            terrain_results = []
            for location in ontology_manager.graph.objects(situation_node, ns.hasì§€í˜•ì…€):
                terrain_data = {'location': str(location)}
                for terrain_type in ontology_manager.graph.objects(location, ns.ì§€í˜•ìœ í˜•):
                    terrain_data['terrain_type'] = str(terrain_type)
                terrain_results.append(terrain_data)
            
            if terrain_results:
                terrain_uri = terrain_results[0].get('location')
                terrain_name = terrain_results[0].get('terrain_type', '')
                env_info['ì§€í˜•'] = str(terrain_name) if terrain_name else 'í‰ì§€'
                
                # ê¸°ìƒìƒí™© ì¡°íšŒ
                weather_results = []
                for s, p, o in ontology_manager.graph.triples((None, ns.ì§€í˜•ì…€ID, URIRef(terrain_uri))):
                    for type_val in ontology_manager.graph.objects(s, ns.ê¸°ìƒìœ í˜•):
                        weather_results.append({'ê¸°ìƒìœ í˜•': str(type_val)})
                if weather_results:
                    env_info['ê¸°ìƒ'] = str(weather_results[0].get('ê¸°ìƒìœ í˜•', 'ë§‘ìŒ'))
                else:
                    env_info['ê¸°ìƒ'] = 'ë§‘ìŒ'  # ê¸°ë³¸ê°’
            else:
                env_info['ì§€í˜•'] = 'í‰ì§€'
                env_info['ê¸°ìƒ'] = 'ë§‘ìŒ'
            
            # ì‹œê° ë° ê³„ì ˆ ì •ë³´ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
            from datetime import datetime
            now = datetime.now()
            hour = now.hour
            if 6 <= hour < 18:
                env_info['ì‹œê°'] = 'ë‚®'
            else:
                env_info['ì‹œê°'] = 'ì•¼ê°„'
            
            month = now.month
            if month in [12, 1, 2]:
                env_info['ê³„ì ˆ'] = 'ê²¨ìš¸'
            elif month in [3, 4, 5]:
                env_info['ê³„ì ˆ'] = 'ë´„'
            elif month in [6, 7, 8]:
                env_info['ê³„ì ˆ'] = 'ì—¬ë¦„'
            else:
                env_info['ê³„ì ˆ'] = 'ê°€ì„'
                
        except Exception:
            # ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            env_info = {
                'ê¸°ìƒ': 'ë§‘ìŒ',
                'ì§€í˜•': 'í‰ì§€',
                'ì‹œê°': 'ë‚®',
                'ê³„ì ˆ': 'ë´„'
            }
        
        return env_info
    
    def _extract_historical_success(self, context: Dict) -> float:
        """ê³¼ê±° ì„±ê³µë¥  ì¶”ì¶œ (RAG ê²°ê³¼ ê¸°ë°˜)"""
        rag_results = context.get("rag_results", [])
        
        if rag_results:
            success_keywords = ['ì„±ê³µ', 'íš¨ê³¼ì ', 'ìŠ¹ë¦¬', 'ì™„ë£Œ', 'ë‹¬ì„±']
            success_count = 0
            
            for result in rag_results:
                if isinstance(result, dict):
                    text = result.get('text', '')
                else:
                    text = str(result)
                
                if any(keyword in text for keyword in success_keywords):
                    success_count += 1
            
            if len(rag_results) > 0:
                return success_count / len(rag_results)
        
        return 0.5  # ê¸°ë³¸ê°’
    
    def _extract_chain_score(self, context: Dict) -> float:
        """ì²´ì¸ ê¸°ë°˜ ì ìˆ˜ ì¶”ì¶œ"""
        chain_info = context.get("chain_info", {})
        
        if chain_info:
            # ì²´ì¸ ìš”ì•½ì—ì„œ í‰ê·  ì ìˆ˜ ì‚¬ìš©
            chain_summary = chain_info.get("summary", {})
            avg_score = chain_summary.get("avg_score", 0.0)
            
            # ì²´ì¸ ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            return min(1.0, max(0.0, avg_score))
        
        return 0.5  # ê¸°ë³¸ê°’
    
    def run_intel_rules(self, context: Dict) -> Dict:
        """
        ì²©ë³´ ê·œì¹™ ì‹¤í–‰
        
        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬ (intel DataFrame ë“± í¬í•¨ ê°€ëŠ¥)
            
        Returns:
            ì²©ë³´ í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        intel_df = context.get("intel")
        
        if intel_df is None or (isinstance(intel_df, pd.DataFrame) and intel_df.empty):
            return {
                "status": "No Intel Data",
                "TrustScore": 0.0
            }
        
        # ê¸°ë³¸ ì‹ ë¢°ë„ ê³„ì‚°
        if isinstance(intel_df, pd.DataFrame):
            # Reliability ë˜ëŠ” confidence ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í‰ê·  ê³„ì‚°
            if "Reliability" in intel_df.columns:
                trust_score = float(intel_df["Reliability"].mean())
            elif "confidence" in intel_df.columns:
                trust_score = float(intel_df["confidence"].mean())
            elif "ì‹ ë¢°ë„" in intel_df.columns:
                trust_score = float(intel_df["ì‹ ë¢°ë„"].mean())
            else:
                # ê¸°ë³¸ê°’
                trust_score = 0.75
        else:
            trust_score = 0.75
        
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒíƒœ ê²°ì •
        if trust_score > 0.8:
            status = "Reliable"
        elif trust_score > 0.5:
            status = "Moderate"
        else:
            status = "Unreliable"
        
        return {
            "TrustScore": round(trust_score, 2),
            "Status": status,
            "IntelCount": len(intel_df) if isinstance(intel_df, pd.DataFrame) else 0
        }
    
    def run_ccir_rules(self, context: Dict) -> Dict:
        """
        CCIR ì¶”ì²œ ê·œì¹™ ì‹¤í–‰
        
        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
                - classification: ë¶„ë¥˜ ê²°ê³¼ (PIR, FFIR, EEFI)
                - asset_recommendation: ìì‚° ì¶”ì²œ ê²°ê³¼
                - request_management: ìš”ì²­ ê´€ë¦¬ ê²°ê³¼
                - dynamic_update: ë™ì  ê°±ì‹  ê²°ê³¼
                - situation_id: ìƒí™© ID
                - threat_level: ìœ„í˜‘ ìˆ˜ì¤€
                
        Returns:
            CCIR ì¶”ì²œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        classification = context.get("classification", {})
        asset_recommendation = context.get("asset_recommendation", {})
        request_management = context.get("request_management", {})
        dynamic_update = context.get("dynamic_update", {})
        threat_level = context.get("threat_level", 0.5)
        
        # CCIR ì¹´í…Œê³ ë¦¬
        category = classification.get("category", "UNKNOWN")
        confidence = classification.get("confidence", 0.5)
        
        # ìš°ì„ ìˆœìœ„
        priority = request_management.get("priority", "MEDIUM")
        priority_score = request_management.get("priority_score", 0.5)
        
        # ì¶”ì²œ ìì‚°
        recommended_assets = asset_recommendation.get("recommended_assets", [])
        
        # ë™ì  ê°±ì‹  í•„ìš” ì—¬ë¶€
        needs_update = dynamic_update.get("needs_update", False) if dynamic_update else False
        
        # ì¢…í•© í‰ê°€ ì ìˆ˜ ê³„ì‚°
        evaluation_score = (
            confidence * 0.3 +  # ì •ë³´ í’ˆì§ˆ
            priority_score * 0.25 +  # ì ì‹œì„±
            (len(recommended_assets) / 5.0) * 0.25 +  # ê´€ë ¨ì„± (ìì‚° ìˆ˜)
            (1.0 if needs_update else 0.5) * 0.2  # ì™„ì „ì„± (ê°±ì‹  í•„ìš” ì—¬ë¶€)
        )
        
        # ìƒíƒœ ê²°ì •
        if evaluation_score >= 0.8:
            status = "Excellent"
        elif evaluation_score >= 0.6:
            status = "Good"
        elif evaluation_score >= 0.4:
            status = "Moderate"
        else:
            status = "Poor"
        
        return {
            "CCIRCategory": category,
            "Confidence": round(confidence, 2),
            "Priority": priority,
            "PriorityScore": round(priority_score, 2),
            "RecommendedAssets": len(recommended_assets),
            "AssetDetails": recommended_assets[:3],  # ìƒìœ„ 3ê°œë§Œ
            "NeedsUpdate": needs_update,
            "EvaluationScore": round(evaluation_score, 2),
            "Status": status,
            "ThreatLevel": threat_level,
            "Timestamp": pd.Timestamp.now().isoformat()
        }
    
    def run_custom_rules(self, context: Dict, rules: List[Dict]) -> Dict:
        """
        ì»¤ìŠ¤í…€ ê·œì¹™ ì‹¤í–‰
        
        Args:
            context: ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
            rules: ê·œì¹™ ë¦¬ìŠ¤íŠ¸ [{"condition": ..., "action": ...}]
            
        Returns:
            ê·œì¹™ ì‹¤í–‰ ê²°ê³¼
        """
        results = []
        for rule in rules:
            condition = rule.get("condition")
            action = rule.get("action")
            
            # ê°„ë‹¨í•œ ì¡°ê±´ í‰ê°€ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ í‰ê°€ ë¡œì§ í•„ìš”)
            if self._evaluate_condition(condition, context):
                results.append(action)
        
        return {"applied_rules": results}
    
    def _evaluate_condition(self, condition: Dict, context: Dict) -> bool:
        """
        ì¡°ê±´ í‰ê°€ (ê°„ë‹¨í•œ êµ¬í˜„)
        
        Args:
            condition: ì¡°ê±´ ë”•ì…”ë„ˆë¦¬
            context: ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            ì¡°ê±´ ë§Œì¡± ì—¬ë¶€
        """
        # ê°„ë‹¨í•œ êµ¬í˜„ ì˜ˆì‹œ
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì¡°ê±´ í‰ê°€ ë¡œì§ í•„ìš”
        return True


    def analyze_situation_hypothesis(self, query: str, context: Optional[Dict] = None) -> List[str]:
        """
        ìƒí™© ê°€ì„¤ ë¶„ì„ (Chatbot RAG ì§€ì›ìš©)
        ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ìˆ ì  ê°€ì„¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            context: ìƒí™© ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì )
            
        Returns:
            ê°€ì„¤ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
        """
        hypotheses = []
        
        # 1. í‚¤ì›Œë“œ ê¸°ë°˜ ë‹¨ìˆœ ê°€ì„¤ (Example)
        if "ìœ„í˜‘" in query or "ì " in query:
            # TODO: ì‹¤ì œ ì˜¨í†¨ë¡œì§€ì—ì„œ ê°€ì¥ ìœ„í˜‘ë„ê°€ ë†’ì€ ì  ë¶€ëŒ€ë¥¼ ì¡°íšŒí•˜ì—¬ ë™ì  ìƒì„±
            hypotheses.append("ì  ê¸°ê°‘ë¶€ëŒ€ì˜ ì ‘ê·¼ì´ ì˜ˆìƒë˜ë¯€ë¡œ ëŒ€ì „ì°¨ ì¥ì• ë¬¼ ì„¤ì¹˜ì™€ ê³µì¤‘ ì§€ì› ìš”ì²­ì´ íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            hypotheses.append("ì‚°ì•… ì§€í˜•ì„ í™œìš©í•œ ë§¤ë³µ ê³µê²©ì´ ì  ê¸°ë™ì„ ì§€ì—°ì‹œí‚¤ëŠ” ë° ìœ ë¦¬í•©ë‹ˆë‹¤.")
            
        if "ë°©ì–´" in query:
             hypotheses.append("í˜„ì¬ ì „ë ¥ë¹„ê°€ ì—´ì„¸ì´ë¯€ë¡œ ì§€ì—° ì‘ì „ í›„ ì£¼ë°©ì–´ì„ ì—ì„œ ê²°ì „ì„ ì¹˜ë¥´ëŠ” ê²ƒì´ êµë¦¬ì— ë¶€í•©í•©ë‹ˆë‹¤.")

        # 2. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°€ì„¤ (ë‚ ì”¨, ì§€í˜• ë“±)
        if context:
            weather = context.get('weather', '')
            terrain = context.get('terrain', '')
            
            if 'rain' in str(weather).lower() or 'ë¹„' in str(weather):
                 hypotheses.append("ìš°ì²œìœ¼ë¡œ ì¸í•´ ê¸°ê°‘ ë¶€ëŒ€ì˜ ê¸°ë™ ì†ë„ê°€ 70% ìˆ˜ì¤€ìœ¼ë¡œ ê°ì†Œí•  ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
            
            if 'mountain' in str(terrain).lower() or 'ì‚°' in str(terrain):
                 hypotheses.append("ì‚°ì•… ì§€í˜•ì€ ë°©ì–´ìì—ê²Œ ìœ ë¦¬í•˜ë©°, ê³µê²©ìì˜ í†µì‹  ë° ê´€ì¸¡ì„ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                 
        return hypotheses
